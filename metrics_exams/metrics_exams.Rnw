\documentclass[pdftex,12pt,a4paper]{article}


<<"init",echo=FALSE,include=FALSE>>=
library("ggplot2")
library("knitr")
# library("plyr")
library("dplyr")
library("reshape2")
library("xtable")
library("gridExtra")
library("lmtest")
library("texreg")
library("pander")
opts_chunk$set(cache=FALSE,
               dev="cairo_pdf",
               warning=FALSE,
               tidy=FALSE,
               echo=FALSE)
options(scipen=10)
theme_set(theme_bw())

load(file="exam_data.Rdata")
@

\input{title_bor_utf8} % use local copy
\input{emetrix_preamble} % use local copy
\unitlength=0.6mm

\title{Подборка экзаменов по эконометрике. \\Факультет экономики, НИУ-ВШЭ}
\date{\today}
\author{Коллектив кафедры \\
математической экономики и эконометрики,\\
 фольклор}


%%%%%%%%%%%%%%%%%% вставки
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Списки без уродских отступов
\newenvironment{enumerate*}{
\begin{enumerate}
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}

\newenvironment{itemize*}{
\begin{itemize}
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\abovedisplayskip=0mm
\abovedisplayshortskip=0mm
\belowdisplayskip=0mm
\belowdisplayshortskip=0mm
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newenvironment{centered}{%
  \begin{list}{}{%
    \topsep0pt
  }
  \centering
  \item[]
}
{\end{list}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[sorting=none, backend=biber]{biblatex}

\usepackage{filecontents}
\begin{filecontents}{metrics_exams.bib}
@misc{mathoverflow0trace,
  title={Смысл следа матрицы},
  url={http://mathoverflow.net/questions/13526/}
}

\end{filecontents}
\addbibresource{metrics_exams.bib}










\begin{document}
\maketitle

\tableofcontents{}


\parindent=0 pt % no indent

\section{Описание}

\section{Вечное}

\subsection{Гимн-памятка для эконометриста}

Эмилю Борисовичу Ершову посвящается

\begin{verse}
Ничего на свете лучше нету, \\
Чем оценивать параметр «бета»! \\
Лучшее оружие демократа --- \\
Метод наименьшего квадрата!
\end{verse}

\begin{verse}
Если вдруг подавит вас депрессия, \\
Виновата, значит, здесь дисперсия. \\
Убери гетероскедастичность, \\
Это придаёт оптимистичность.
\end{verse}

\begin{verse}
Если в данных автокорреляция, \\
Всё, что посчитал ты, --- профанация. \\
Применяй, не глядя исподлобия, \\
Максимальное правдоподобие.
\end{verse}

\begin{verse}
Если ощутил ты свою бренность, \\
Не иначе это эндогенность. \\
Соглашайся выдать алименты \\
Тем, кто знает, где взять инструменты.
\end{verse}

\begin{verse}
Где б ты ни был, в саклях и ярангах \\
Применяй везде условья ранга. \\
Помни также: лучшая зарядка --- \\
Выполнить условие порядка.
\end{verse}

\begin{verse}
Мы своё призванье не забудем! \\
BLUE-оценки мы предъявим людям! \\
Нам законов априорных своды \\
Не понизят степеней свободы!
\end{verse}



\subsection{Прошение о повышение оценки}

\vspace{10pt}
От ...............................

\vspace{10pt}
Группа ......

\vspace{10pt}
Я считаю, что моя итоговая оценка по курсу ...................... должна быть исправлена с .... на ... по следующим причинам (обведите нужные).

\begin{enumerate}
\item Это единственная плохая оценка в моей зачетке
\item Тот, кто полностью списал мою работу, получил более высокую оценку
\item Тот, у кого я полностью списал работу, получил более высокую оценку
\item Из-за низкого рейтинга меня могут не взять в
\begin{enumerate}
\item РЭШ
\item СМЕРШ
\item МГУ
\item На Луну
\item ..............
\end{enumerate}
\item Мне нужно получить 10, чтобы компенсировать 4 по ......................
\item Меня лишат стипендии
\item Я не успел договориться с тётечками из копировального отдела и раздобыть варианты контрольной, потому что ..............................................
\item Я не посещал лекции, а тот, чьими конспектами я пользовался, не записал материал, необходимый для сдачи контрольных и домашек
%\item Я изучил основные идеи, а на контрольных требовалось знание мельчайших деталей
%\item Я изучил мельчайшие детали, а на контрольных требовались общие идеи
\item Я отлично понимаю теорию, просто не умею решать задачи
\item Я умею решать все задачи, а на контрольной требовалось знание теории
\item У лектора/семинариста были предрассудки против ...................
\item Все вопросы на экзамене допускали двойную трактовку. Я считаю, что не должен нести наказание за то, что мое мнение --- особенное
\item Если я получу плохую оценку отец отберет у меня ключи от машины
\item Я не мог/могла заниматься из-за необходимости разгружать вагоны по ночам
\item Нам сказали использовать творческий подход, но не объяснили, что это означает
\item Я использовал в домашках творческий подход,  но мне было сказано, что я несу всякую чушь
\item Все остальные преподаватели согласны повысить мою оценку
\item Семинары и лекции начинались:
\begin{enumerate}
\item слишком рано, я еще спал
\item слишком поздно, я уже спал
\item в обеденное время, я был голодный
\end{enumerate}
\item Причина по которой я получил низкую оценку проста --- я очень честный. Не хочу ничего говорить о моих одногруппниках
\item У меня нет особой причины, я просто хочу оценку повыше
\end{enumerate}


\vspace{10pt}
Дата ................

\vspace{10pt}
Подпись ...............

\section{Немного теории}

\subsection{Конвенция об обозначениях}

\begin{itemize}
\item $y$ --- вектор-столбец зависимых переменных размера $(n \times 1)$, наблюдаемый случайный

\item $\beta$ --- вектор-столбец неизвестных коэффициентов размера $(k \times 1)$, ненаблюдаемый, неслучайный

\item $\hy$ --- вектор столбец прогнозов для $y$, полученных по некоторой модели, размера $(n \times 1)$, наблюдаемый, случайный

\item $\hb$ --- вектор-столбец оценок $\beta$ размера $(k \times 1)$, наблюдаемый, случайный

\item $X$ --- матрица всех объясняющих переменных, размера $(n \times k)$. Известная, стохастическая или детерминированная в зависимости от парадигмы.

\item $\e$ --- вектор-столбец случайных ошибок размера $(n \times 1)$, ненаблюдаемый случайный

\item $\he$ --- вектор-столбец остатков модели размера $(n \times 1)$, наблюдаемый случайный

\item $c$ --- вектор из единиц
\end{itemize}

В некоторых учебниках используется обозначение $Y$ для исходного вектора зависимых переменных, а $y$ --- для центрированного, т.е.  $y=Y-\bar{Y}$. В этом документе $y$ обозначает исходный вектор $y$.


\subsection{Свойства ковариационных матриц}

Здесь $y$ --- вектор-столбец $n\times 1$, $z$ --- вектор-столбец $k\times 1$, $A$ --- матрица констант подходящего размера, $b$ --- вектор констант подходящего размера.

\begin{enumerate}
\item $\E(Ay+b)=A\E(y)+b$, $\E(yA+b)=\E(y)A+b$
\item $\Cov(y, z) = \E(yz') - \E(y)\E(z')$
\item $\Var(y) = \E(yy') - \E(y)\E(y')$
\item $\Cov(Ay + b, z) = A\Cov(y, z)$, $\Cov(y, Az + b) = \Cov(y, z) A'$
\item $\Var(Ay+b)=A\Var(y)A'$
\item $\Cov(y,z)=\Cov(z,y)'$
\end{enumerate}

\subsection{ТГМ. Детерминированные регрессоры}


\subsection{ТГМ. Стохастические регрессоры}


Если:

\begin{enumerate}
\item Истинная зависимость имеет вид $y_i=\beta_1 + \beta_2 x_{i2} + \ldots + \beta_k x_{ik}+\varepsilon_i$

В матричном виде: $y=X\beta + \varepsilon$
\item С помощью МНК оценивается регрессия $y$ на константу, $x_{.2}$, $x_{.3}$, \ldots, $x_{.k}$

В матричном виде: $\hat{\beta}=(X'X)^{-1}X'y$
\item Наблюдений больше, чем оцениваемых коэффициентов $\beta$: $n>k$
\item Строгая экзогенность: $E(\varepsilon_i | \text{ все } x_{ij})=0$

В матричном виде: $E(\varepsilon_i | X)=0$
\item Условная гомоскедастичность: $E(\varepsilon_i^2 | \text{ все } x_{ij})=\sigma^2$

В матричном виде: $E(\varepsilon_i^2 | X)=\sigma^2$
\item  $Cov(\varepsilon_i,\varepsilon_j | X)=0$ при $i \neq j$
\item  вектора $(x_{i.},y_i)$ --- независимы и одинаково распределены
\item  с вероятностью 1 среди регрессоров нет линейно зависимых
$rank(X)=k$
$det(X'X)\neq 0$
$(X'X)^{-1}$ существует
\end{enumerate}

То:
% (свойства для конечных выборок, не требующие нормальности $\varepsilon$):

\begin{enumerate}
\item (тГМ) МНК оценки $\hat{\beta}$ линейны по $y$:
$\hat{\beta_j}=c_1 y_1 + ... + c_n y_n$
\item  (тГМ) МНК оценки несмещенные. А именно, $E(\hat{\beta} |X )=\beta$, и в частности $E(\hat{\beta})=\beta$
\item  (тГМ) МНК оценки эффективны среди линейных несмещённых оценок. Для любой альтернативной оценки $\hat{\beta}^{alt}$ удовлетворяющей свойствам 1 и 2:
$Var(\hat{\beta}_j^{alt} | X)\geq Var(\hat{\beta}_j | X)$
$Var(\hat{\beta}_j^{alt} )\geq Var(\hat{\beta}_j )$
\item  $Var(\hat{\beta} | X )=\sigma^2 (X'X)^{-1}$
\item $Cov(\hat{\beta},\hat{\varepsilon} | X)=0$
\item  $E(\hat{\sigma}^2 |X ) = \sigma^2$, и $E(\hat{\sigma}^2 ) = \sigma^2$ ?остается ли при условной ГК?
\end{enumerate}

Если дополнительно к предпосылкам теоремы Гаусса-Маркова известно, что $\varepsilon |X \sim N$, то:

\begin{enumerate}
\item  МНК оценки эффективны среди всех несмещённых оценок.
\item $t|X \sim t_{n-k}$, $t\sim t_{n-k}$
\item  $RSS/\sigma^2 |X \sim \chi^2_{n-k}$, $RSS/\sigma^2 \sim \chi^2_{n-k}$
\item $F$ тест $F|X \sim F$
\end{enumerate}

Если дополнительно к предпосылкам теоремы Гаусса-Маркова известно, что $n\to \infty$, то:

\begin{enumerate}
\item  $\hat{\beta} \to \beta$ по вероятности

\item $t \to N(0,1)$
\item $rF \to \chi^2_r$, $r$ --- число ограничений
\item $nR^2 \to \chi^2_{k-1}$
\item $\frac{RSS}{n-k} \to \sigma^2 $
\end{enumerate}

\subsection{Ликбез по линейной алгебре}

\begin{definition}
Неформально. Если матрица $A$ квадратная, то её определителем называется площадь/объём параллелограмма/параллелепипеда образованного векторами-столбцами матрицы. Знак определителя задаётся порядком следования векторов.
\end{definition}


Свойства определителя:
\begin{enumerate}
\item $\det(AB)=\det(A)\det(B)=\det(BA)$, если $A$ и $B$ квадратные
\item $\det(A)=\prod \lambda_i$, где $\lambda_i$ --- собственное число матрицы $A$, возможно комплексное.
\end{enumerate}


\begin{definition}
Ненулевой вектор $x$ называется собственным вектором матрицы $A$, если при умножении на матрицу $A$ он остается на той же прямой, т.е. $Ax=\lambda x$.
\end{definition}

\begin{definition}
Число $\lambda$ называется собственным числом матрицы $A$, если существует вектор $x$, который при умножении на матрицу $A$ изменяется в $\lambda$ раз, т.е. $Ax=\lambda x$.
\end{definition}

\begin{definition}
Если матрица $A$ квадратная, то её следом называется сумма диагональных элементов, $\trace(A)=\sum a_{ii}$.
\end{definition}

Свойства следа:
\begin{enumerate}
\item $\trace(A+B)=\trace(A)+\trace(B)$
\item $\trace(AB)=\trace(BA)$, если $AB$ и $BA$ существуют. При этом $A$ и $B$ могут не быть квадратными матрицами.
\item $\trace(A)=\sum \lambda_i$, где $\lambda_i$ --- собственное число матрицы $A$, возможно комплексное.
\end{enumerate}


Смысл следа. Если умножение на матрицу $A$ --- это проецирование, то есть $Ax$ --- есть проекция вектора $x$ на некоторое подпространство, то $\trace(A)$ --- размерность этого подпространства. Действительно, если $A$ --- проектор, то $A^2=A$ и собственные числа матрицы $A$ равны нулю или единице. Поэтому $\trace(A)$ равен количеству собственных чисел равных единице. И, следовательно, $\trace(A)$ равен $\rank(A)$, то есть размерности пространства, на которое матрица $A$ проецирует вектора. У следа матрицы есть и другие смыслы \autocite{mathoverflow0trace}.


\subsection{Ожидание от RSS}

\begin{theorem}
След и математическое ожидание можно переставлять, $\E(\tr(A))=\tr(\E(A))$.
\end{theorem}

\begin{theorem}
Математическое ожидание квадратичной формы
\begin{equation}
\E(x'Ax)=\tr(A\Var(x))+\E(x')A\E(x)
\end{equation}
\end{theorem}
\begin{proof}
Мы будем пользоваться простым приёмом. Если $u$ --- это скаляр, вектор размера 1 на 1, то $\tr(u)=u$.

Поехали,
\begin{equation}
\E(x'Ax)=\E(\tr(x'Ax))=\E(\tr(Axx'))=\tr(\E(Axx'))=\tr(A\E(xx'))
\end{equation}

По определению дисперсии, $\Var(x)=\E(xx')-\E(x)\E(x')$. Поэтому:
\begin{equation}
\tr(A\E(xx'))=\tr(A(\Var(x)+\E(x)\E(x')))=\tr(A\Var(x))+\tr(A\E(x)\E(x'))
\end{equation}

И готовимся снова использовать приём $\tr(u)=u$:
\begin{equation}
\tr(A\Var(x))+\tr(A\E(x)\E(x'))=\tr(A\Var(x))+\tr(\E(x')A\E(x))=
\tr(A\Var(x))+\E(x')A\E(x)
\end{equation}

\end{proof}


\subsection{Устоявшиеся слова}

Выражение «гипотеза о значимости отдельного коэффициента» на самом деле означает «гипотеза о незначимости отдельного коэффициента», т.к. де-факто проверяется гипотеза $H_0$: $\beta_j=0$.

Выражение «гипотеза о значимости регрессии в целом» или «гипотеза об адекватности регрессии» на самом деле означает «гипотеза о незначимости регрессии в целом», т.к. проверяется $H_0$: $\beta_2=\ldots=\beta_k=0$.

В некоторых источниках гипотезу об адекватности регрессии ошибочно обозначают $H_0$: $R^2=0$. Эту ошибку не нужно повторять.

Гипотезы имеет смысл проверять о ненаблюдаемых величинах, а величина $R^2$ является наблюдаемой. И если уж на то пошло, то проверить гипотезу о том, что $R^2=0$ тривиально. Для этого не нужно знать ничего из теории вероятностей, достаточно просто сравнить посчитанное значение $R^2$ с нулём.

Более того, даже корректировка $H_0$: $\E(R^2)=0$ неверна. В модели, где в регрессоры включена только константа, величина $R^2$ тождественно равна нулю, поэтому $\E(R^2)=0$ и проверять такую гипотезу бессмысленно. В модели, где в регрессоры включено что-то помимо константы, $R^2$ является неотрицательной случайной величиной с $\P(R^2>0)>0$. Поэтому а-приори $\E(R^2)>0$ и проверка гипотезы $H_0$: $\E(R^2)=0$ снова бессмысленна.

Кстати, обозначение $H_0$ по-английски читается как «H naught», а не «H zero» или «H null». Также корректно говорить «the null hypothesis».



\nocite{*}
\printbibliography

\section{2012-2013}

\subsection{Праздник 1. Пролетарий на коня!}

\begin{center}
\includegraphics[height=3in]{proletarii.jpg}
\end{center}
\begin{enumerate}
\item Найдите длины векторов $a=(1,2,3)$ и $b=(1,0,-1)$ и косинус угла между ними.
\item Сформулируйте теорему о трёх перпендикулярах.
\item Сформулируйте и докажите теорему Пифагора.
\item Для матрицы

$A=\left(%
\begin{array}{ccc}
  2 & 3 & 0 \\
  3 & 10 & 0 \\
  0 & 0 & -1 \\
\end{array}%
\right)$ \\

\begin{enumerate}
\item Найдите собственные числа и собственные векторы матрицы.
\item Найдите обратную матрицу, $A^{-1}$, ее собственные векторы и собственные числа.
\item Представьте матрицу $A$ в виде $A=CDC^{-1}$, где $D$ --- диагональная матрица.
\item Представьте $A^{2012}$ в виде произведения трёх матриц.
\end{enumerate}

\item Вася и Петя независимо друг от друга решают тест по теории вероятностей. В тесте всего два вопроса. На каждый вопрос два варианта ответа. Петя знает решение каждого вопроса с вероятностью $0{,}7$. Если Петя не знает решения, то он отвечает равновероятно наугад. Вася знает решение каждого вопроса с вероятностью $0{,}5$. Если Вася не знает решения, то он отвечает равновероятно наугад.
\begin{enumerate}
\item Какова вероятность того, что Петя правильно ответил на оба вопроса?
\item Какова вероятность того, что Петя правильно ответил на оба вопроса, если его ответы совпали с Васиными?
\item Чему равно математическое ожидание числа Петиных верных ответов?
\item Чему равно математическое ожидание числа Петиных верных ответов, если его ответы совпали с Васиными?
\end{enumerate}

\item Для случайных величин $X$ и $Y$ заданы следующие значения: $\E(X)=1$, $\E(Y)=4$, $\E(XY)=8$, $\Var(X)=\Var(Y)=9$. Для случайных величин $U=X+Y$ и $V=X-Y$ вычислите:
\begin{enumerate}
\item $\E(U)$, $\Var(U)$, $\E(V)$, $\Var(V)$, $\Cov(U,V)$
\item Можно ли утверждать, что случайные величины U и V независимы?
\end{enumerate}

\item Вася ведёт блог. Обозначим $X_i$ --- количество слов в $i$--ой записи. После первого года он по своим записям обнаружил, что $\bar{X}_{200}=95$ и выборочное стандартное отклонение равно 282 слова. На уровне значимости $\alpha=0.10$ проверьте гипотезу о том, что $\mu=100$ против альтернативной гипотезы $\mu\neq 100$. Найдите также точное P-значение.


\end{enumerate}



\subsection{Праздник 2. Базовая задача}


\begin{comment}
Плывут облака \\
Отдыхать после знойного дня,\\

Стремительных птиц \\
Улетела последняя стая. \\

Гляжу я на горы, \\
И горы глядят на меня, \\

И долго глядим мы,\\
Друг другу не надоедая.\\

\quote{Ли Бо, Одиноко сижу в горах Цзинтиншань}

\vspace{30pt}
\end{comment}



\begin{enumerate}
\item Случайные величины $Z_i$ независимы и нормально распределены $N(0,1)$. Для их суммы $S=\sum_{i=1}^n Z_i$ найдите $\E(S)$ и $\Var(S)$.
\item Социологическим опросам доверяют 70\% жителей. Те, кто доверяют
опросам, на все вопросы отвечают искренне; те, кто не доверяют, отвечают равновероятно наугад. Социолог Петя в анкету очередного опроса включил вопрос «Доверяете ли Вы социологическим опросам?»
\begin{enumerate}
\item Какова вероятность, что случайно выбранный респондент ответит «Да»?
\item Какова вероятность того, что он действительно доверяет, если известно, что он ответил
«Да»?
\end{enumerate}
\item Регрессионная модель  задана в матричном виде при помощи уравнения $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что

$y=\left(
\begin{array}{c}
1\\
2\\
3\\
4\\
5
\end{array}\right)$,
$X=\left(\begin{array}{ccc}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 0 & 1 \\
1 & 1 & 0 \\
1 & 1 & 0
\end{array}\right)$.


Для удобства расчетов приведены матрицы


$X'X=\left(
\begin{array}{ccc}
5 & 2 & 1\\
2 & 2 & 0\\
1 & 0 & 1
\end{array}\right)$ и $(X'X)^{-1}=\frac{1}{2}\left(
\begin{array}{ccc}
1 & -1 & -1 \\
-1 & 2 & 1 \\
-1 & 1 & 3
\end{array}\right)$.

\begin{enumerate}
\item Укажите число наблюдений.

\item Укажите число регрессоров с учетом свободного члена.

\item Рассчитайте при помощи метода наименьших квадратов $\hb$, оценку для вектора неизвестных коэффициентов.

\item Рассчитайте $TSS=\sum (y_i-\bar{y})^2$, $RSS=\sum (y_i-\hat{y}_i)^2$ и $ESS=\sum (\hat{y}_i-\bar{y})^2$.

\item Чему равен $\he_4$, МНК-остаток регрессии, соответствующий 4-ому наблюдению?

\item Чему равен $R^2$  в модели?

\item Рассчитайте несмещенную оценку для неизвестного параметра $\sigma^2$ регрессионной модели.

\item Рассчитайте $\widehat{\Var}(\hb)$, оценку для ковариационной матрицы вектора МНК-коэффициентов $\hb$.

\item Найдите $\widehat{\Var}(\hb_1)$, несмещенную оценку дисперсии МНК-коэффициента $\hb_1$.

\item Найдите $\widehat{\Cov}(\hb_1,\hb_2)$, несмещенную оценку ковариации МНК-коэффициентов $\hb_1$ и $\hb_2$.

\item Найдите $\widehat{\Var}(\hb_1+\hb_2)$

\item Найдите $\hCorr(\hb_1,\hb_2)$, оценку коэффициента корреляции МНК-коэффициентов $\hb_1$ и $\hb_2$.

\item Найдите $se(\hb_1)$, стандартную ошибку МНК-коэффициента $\hb_1$.

\end{enumerate}
\item В классической линейной модели предполагается, что $\E(\e)=0$, $\Var(\e)=\sigma^2 I$. Найдите $\Cov(y,\he)$, $\Cov(\hy,\he)$.

\end{enumerate}


\subsection{Праздник 3. Дню рождения буквы «ё» посвящается\ldots}

\begin{enumerate}
\item Выберите верные варианты.

\begin{enumerate}
\item Побасёнка --- Побасенка
\item Вёдро --- Ведро
\item Гренадёр --- Гренадер
\item Новорождённый --- Новорожденный
\item Бытиё --- Бытие
\item Опёка --- Опека
\item Сёрфинг --- Серфинг
\item Пафнутий Львович Чебышёв --- Пафнутий Львович Чебышев
\item Лёв Николаевич Толстой --- Лев Николаевич Толстой
\end{enumerate}


\item По 47 наблюдениям оценивается зависимость доли мужчин занятых в сельском хозяйстве от уровня образованности и доли католического населения по Швейцарским кантонам в 1888 году.

\[Agriculture_i=\beta_1+\beta_2 Examination_i+\beta_3 Catholic_i+\varepsilon_i\]

<<echo=FALSE,message=FALSE>>=
# library(Hmisc)
library(lmtest)
library(apsrtable)
library(xtable)
h <- swiss
model1 <- glm(Agriculture~Examination+Catholic,data=h)
coef.t <- coeftest(model1)
dimnames(coef.t)[[2]] <- c("Оценка","Ст. ошибка",  "t-статистика", "P-значение")
coef.t <- coef.t[,-4]
coef.t[1,1] <- NA
coef.t[2,2] <- NA
coef.t[3,3] <- NA
@

<<echo=FALSE,results='asis'>>=
xtable(coef.t)
@

\begin{enumerate}
\item Заполните пропуски в таблице.
\item Укажите коэффициенты, значимые на 10\% уровне значимости.
\item Постройте 95\%-ый доверительный интервал для коэффициента при переменной Catholic
\end{enumerate}

\newpage

\item Оценивается зависимость уровня фертильности всё тех же швейцарских кантонов в 1888 году от ряда показателей. В таблице представлены результаты оценивания двух моделей.

Модель 1: $Fertility_i=\beta_1+\beta_2 Agriculture_i+\beta_3 Education_i+\beta_4 Examination_i+\beta_5 Catholic_i+\varepsilon_i$

Модель 2: $Fertility_i=\gamma_1+\gamma_2 (Education_i+Examination_i)+\gamma_3 Catholic_i+u_i$

<<echo=FALSE>>=
m1 <- lm(Fertility~Agriculture+Education+Examination+Catholic,data=h)
m2 <- lm(Fertility~I(Education+Examination)+Catholic,data=h)
@

<<echo=FALSE, results='asis'>>=
apsrtable(m1, m2)

@

\begin{enumerate}
\item Посчитайте $RSS$ для каждой модели.
\item Какая модель является ограниченной (короткой), какая --- неограниченной (длинной)?
\item Какие ограничения нужно добавить к неограниченной модели, чтобы получить ограниченную?
\item Найдите наблюдаемое значение $F$ статистики.
\item Отвергается или не отвергается гипотеза об ограничениях?
\end{enumerate}

\end{enumerate}

\subsection{Праздник 4, ML}

\WhiteRoseLine

\begin{enumerate}
\item Наблюдения $X_1,X_2,\ldots,X_n$ независимы и одинаково распределены с функцией плотности $f(x)=\frac{a(\ln(x))^{a-1}}{x}$ при $x\in [1;e]$. По 100 наблюдениям известно, что $\sum_{i=1}^{100} \ln(\ln(X_i))=-20$
\begin{enumerate}
\item Оцените параметр $a$ методом максимального правдоподобия
\item Проверьте гипотезу о том, что $a=5$ против альтернативной $a\neq 5$ с помощью теста отношения правдоподобия, теста Вальда, теста множителей Лагранжа
\item Постройте 95\%-ый доверительный интервал для параметра $a$
\end{enumerate}
\item \useR Фактическое распределение часовой и десятиминутной скорости ветра хорошо приближается распределением Вейбулла. Случайная величина имеет распределение Вейбулла, если её функция плотности при $x>0$ имеет вид
\[
f(x)=\frac{1}{\lambda^k}kx^{k-1}\exp(-x^k/\lambda^k)
\]
\begin{enumerate}
\item Оцените параметры $k$ и $\lambda$ методом максимального правдоподобия
\item Постройте 95\%-ые доверительные интервалы для $k$ и $\lambda$
\end{enumerate}
Часовые данные я не нашёл, нашёл дневные. Данные по среднедневной скорости ветра содержатся в \verb|weather_nov_2012_moskow.csv| в стобике \verb|wind|. Данные взяты с сайта \url{http://www.atlas-yakutia.ru/weather/climate_russia-I.html}.

Hint: \verb|read.csv("filename.csv")|
\end{enumerate}

\RedRoseLine

\begin{enumerate}
\item Купив пачку мэндэмс я насчитал в ней 1 жёлтую, 7 зелёных, 4 оранжевых, 3 коричневых, 2 синих и 1 красную мэндэмсину. С помощью теста отношения правдоподобия проверьте гипотезу, что мэндэмсины всех цветов встречаются равновероятно.
\item \useR Фактическое распределение часовой и десятиминутной скорости ветра хорошо приближается распределением Вейбулла. Случайная величина имеет распределение Вейбулла, если её функция плотности при $x>0$ имеет вид
\[
f(x)=\frac{1}{\lambda^k}kx^{k-1}\exp(-x^k/\lambda^k)
\]
\begin{enumerate}
\item Найдите функцию распределения $F(x)$
\item Выразите медиану распределение Вейбулла, $m$, через параметры $k$ и $\lambda$
\item Оцените параметры $k$ и $\lambda$ методом максимального правдоподобия
\item Постройте 95\%-ые доверительные интервалы для $k$ и $\lambda$
\item Выпишите функцию плотности распределения Вейбулла через $m$ и $k$
\item Проверьте гипотезу о том, что медиана равна 1 м/сек с помощью трёх тестов
\end{enumerate}
Часовые данные я не нашёл, нашёл дневные. Данные по среднедневной скорости ветра содержатся в \verb|weather_nov_2012_moskow.csv| в стобике \verb|wind|. Данные взяты с сайта \url{http://www.atlas-yakutia.ru/weather/climate_russia-I.html}.

\end{enumerate}

\subsection{Праздник 5, 01.04.2013, Гетероскедастичность}

C 1-м апреля!!!

\begin{enumerate}

\item Рождается старичком, умирает младенцем, сегодня празднует день рождения, но не Гоголь.
Кто это? Опишите внешний вид, характер, или нарисуйте его :)

\item Для борьбы с гетероскедастичностью в модели $y_i=\beta_1+\beta_2 x_i+\varepsilon_i$ исследователь перешёл к модели $\tilde{y}_i=\beta_1 \frac{1}{z_i}+\beta_2 \tilde{x}_i+\tilde{\varepsilon}_i$, где $\tilde{x}_i=x_i/z_i$, $\tilde{y}_i=y_i/z_i$, $\tilde{\varepsilon}_i=\varepsilon_i/z_i$.

Какой вид гетероскедастичности предполагался?

\item Василий Аспушкин провёл два разных теста на гетероскедастичность на одном уровне значимости. Оказалось, что в одном из них $H_0$ отвергается, а в другом --- нет.
\begin{enumerate}
\item Почему это могло случиться?
\item Какой же вывод о гетероскедастичности следует сделать Василию? Что можно сказать об уровне значимости предложенного Вами способа сделать вывод?

\end{enumerate}


\item Писатель Василий Аспушкин пишет Большой Роман. Количество страниц, которое он пишет ежедневно, зависит от количества съеденных пирожков, выпитого лимонада и числа посещений Музы.
\[
Stranitsi_i = \beta_1 + \beta_2 Pirojki_i + \beta_3 Limonad_i + \beta_4 Musa_i + \varepsilon_i
\]

Когда идёт дождь, Василий Аспушкин очень волнуется: он ошибочно считает, что музы плохо летают в дождь. Поэтому в дождливые дни дисперсия $\varepsilon_i$ может быть выше.


\begin{enumerate}
\item Отсортировав имеющиеся наблюдения по количеству осадков в день, Настойчивый издатель построил регрессию по 40 самым дождливым дням и получил $RSS=\sum_i (y_i-\hat{y}_i)^2=360$. В регрессии по 40 самым сухим дням $RSS=252$. Всего имеется 100 наблюдений. Проверьте гипотезу о гомоскедастичности. Как называется соответствующий тест?

\item Василий Аспушкин оценил по 100 наблюдениям исходную модель с помощью МНК. А затем построил регрессию квадратов стьюдентизированных остатков на количество осадков и константу. Во второй регрессии $R^2=0.3$. Проверьте гипотезу о гомоскедастичности.

\item Предположим, что дисперсия ошибок линейно зависит от количества осадков.
\begin{enumerate}
\item Как будет выглядеть функция максимального правдоподобия для оценивания коэффициентов исходной модели?
\item Опишите процедуру доступного обобщенного метода наименьших квадратов (FGLS, feasible generalized least squares) применительно к данной ситуации
\end{enumerate}
\end{enumerate}
Hint: Функция плотности одномерного нормального распределения имеет вид
\[
f(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}  \right)
\]
% многомерное
%f(x)=(2\pi)^{-n/2} \det(\Omega)^{-1/2} \exp\left(-\frac{1}{2}(x-\mu)'\Omega^{-1}(x-\mu)\right)


\item В курсе теории вероятностей изучался тест о равенстве математических ожиданий по двум нормальным выборкам при предпосылке о равенстве дисперсий. Предложите состоятельный способ тестировать гипотезу о равенстве математических ожиданий без предпосылки равенства дисперсий.


\end{enumerate}

\subsection{Домашнее задание 3. Знакомство с RLMS}

\begin{enumerate}
\item Прочитайте про RLMS, \url{http://www.hse.ru/rlms/}

Посмотрите описание проекта. Пролистайте вестник RLMS, чтобы иметь представление о том, какие исследования можно строить на основе RLMS.

\item Скачайте любую волну RLMS по своему выбору. Скачайте описание переменных.

Пролистайте описание переменных. Там их больше тысячи. Попадаются довольно прикольные. Мне нравится pc9.6.5a, «У Вас есть GPRS навигатор?»

\item Загрузите данные в R.

Данные RLMS выложены на сайте в формате SPSS. SPSS это потихоньку погибающий статистический пакет для домохозяек. Для чтения формата .sav в таблицу данных R можно сделать так
<<"read sav">>=
library(foreign)
file.name<-"/home/boris/downloads/r20hall23c.sav"
h<-read.spss(file.name,to.data.frame=TRUE)
@
Первая команда, library(foreign), подгружает библиотеку R, в которой содержатся команды для чтения вражеских форматов, spss, stata, etc

Описания переменных при этом также загружаются в таблицу данных. Можно их выделить в отдельный вектор и прочитать, например, про переменную pc9.631a.
<<"description of vars">>=
var.labels<-attr(h,"variable.labels")
var.labels["pc9.631a"]
@

\item Выберите любую количественную переменную в качестве зависимой и несколько переменных в качестве объясняющей.

Цель этой домашки скорее ознакомится с наличием мониторинга RLMS, поэтому можно не сильно заморачиваться с этим этапом. Хотя в реальности тут-то всё самое интересное и начинается. За оригинальные гипотезы будут плюшки.

\item Опишите выбранные переменные.

Постройте симпатичные графики. Посчитайте описательные статистики. Много ли пропущенных наблюдений? Есть ли что-нибудь интересненькое?

\item Постройте регрессию зависимой переменной на объясняющие.

Проверьте гипотезу о значимости каждого полученного коэффициента. Проверьте гипотезу о значимости регрессии в целом. Для нескольких коэффициентов (двух достаточно) постройте 95\%-ый доверительный интервал.

\item Напишите свои пожелания и комментарии.

Какие домашки хочется сделать? Что не ясно в курсе эконометрики? Содержательные комментарии позволяют получить бонус. Искусная лесть оценивается :)

\end{enumerate}

\subsection{Домашнее задание \No $(n+1)$ по эконометрике-1.}

\textbf{Задача 1}. «CAPM»

Оценим модель CAPM по реальным данным:
\begin{enumerate}
\item Коротко сформулируйте теоретические положения модели CAPM. За корректное отделение выводов от предпосылок --- дополнительный бонус.
\item Соберите реальные данные по трём показателям: $R_i$ --- доходность некоей акции за $i$-ый период, $R_{m,i}$ --- рыночная доходность за $i$-ый период, $R_{f,i}$ --- безрисковая доходность за $i$-ый период. Статья \href{http://quantile.ru/06/06-AT.pdf}{quantile.ru/06/06-AT.pdf} в помощь.
\item Представьте информацию графически
\item С помощью МНК оцените модель без константы, $R_i-R_{f,i}=\beta (R_{m,i}-R_{f,i})+\e_i$. Предположим, что $\e_i \sim N(0,\sigma_{\e}^2)$.
\item Прокомментируйте результаты оценивания. В частности, проверьте гипотезы о значимости коэффициента и регрессии в целом.
\item С помощью МНК оцените модель с константой, $R_i-R_{f,i}=\beta_1 + \beta_2 (R_{m,i}-R_{f,i})+\e_i$. Предположим, что $\e_i \sim N(0,\sigma_{\e}^2)$.
\item Прокомментируйте результаты оценивания. В частности, проверьте гипотезы о значимости коэффициентов и регрессии в целом.
\item Труднее всего измерить безрисковую ставку процента. Поэтому предположим, что имеющиеся у нас наблюдения --- это безрисковая ставка, измеренная с ошибкой. Т.е. имеющиеся у нас наблюдения $R_{f,i}$ представимы в виде $R_{f,i}=R_{f,i}^{true}+u_i$, где $u_i \sim N(0,\sigma^2_u)$. Величина $R_{f,i}^{true}$ ненаблюдаема, но именно она входит в модель CAPM. Получается, что оцениваемая модель имеет вид $R_i-R_{f,i}^{true}=\beta (R_{m,i}-R_{f,i}^{true})+\e_i$.
\begin{enumerate}
\item Выпишите функцию правдоподобия для оценки данной модели
\item Найдите оценки $\hb$, $\hs2_{u}$, $\hs2_{\e}$
\item Постройте 95\%-ые доверительные интервалы
\item Проделайте аналогичные действия для модели с константой
\item Сделайте выводы
\end{enumerate}

\end{enumerate}



\textbf{Задача 2}. «Циф\'{и}рьки на мониторе»

При входе на каждую станцию метро есть турникеты. Рядом с турникетами в будке сидит бабушка божий одуванчик. В будке у бабушки висит монитор. На этом мониторе --- прямоугольники с циф\'{и}рьками.
\begin{enumerate}
\item Понаблюдав за изменением циф\'{и}рек, догадайтесь, что они означают.
\item Вечером какого-нибудь буднего дня запишите все цифирьки с монитора на своей родной станции метро.
\item Представьте информацию графически
\item Будем моделировать величину $i$-ой циф\'{и}рьки пуассоновским распределением с математическим ожиданием $\lambda_i$. Предположим также, что $\lambda_i=\beta_1+\beta_2 \cdot i$, где $i$ --- номер турникета считая от будки с бабушкой.
\begin{enumerate}
\item Выпишете функцию правдоподобия
\item Оцените параметры $\beta_1$ и $\beta_2$
\item Оцените ковариационную матрицу оценок $\hb_1$ и $\hb_2$
\item Постройте 95\%-ые асимптотические доверительные интервалы для параметров
\item Проверьте гипотезу о том, что $\beta_2=0$. Альтернативную гипотезу сформулируйте самостоятельно.
\end{enumerate}
\end{enumerate}



PS. Своё смелое творчество в задачах поощряется!

\subsection{Домашнее задание. Титаник.}

Нужно зарегистрироваться на сайте \url{www.kaggle.com} и принять участие в конкурсе «Titanic: Machine Learning from Disaster». Крайний срок сдачи отчёта: в ночь с 14 на 15 апреля 2013 года.

\vspace{15pt}
\WhiteRoseLine
\vspace{15pt}

\begin{enumerate}
\item Домашнее задание можно делать в одиночку или группой из двух человек.
\item А можно всё-таки группой из трёх человек? Нет :)
\item Письменный отчёт  должен содержать как-минимум:
\begin{enumerate}
\item Логин группы
\item Графический анализ имеющихся данных
\item Результаты оценивания logit и probit моделей
\item Графический анализ logit и probit моделей
\item «Если бы я был пассажиром Титаника, то я спасся бы с вероятностью\ldots».

С помощью logit и probit моделей необходимо построить 95\%-ый доверительный интервал для вероятности спасения каждого из участников группы, сдающей домашку. Пол и возраст взять фактические, а остальные объясняющие переменные --- по своему желанию.
\end{enumerate}
\end{enumerate}


\vspace{15pt}
\RedRoseLine
\vspace{15pt}


\begin{enumerate}
\item Домашнее задание можно делать только в одиночку :)
\item Нет, нельзя :)
\item Письменный отчёт  должен содержать как-минимум:
\begin{enumerate}
\item Логин
\item Графический анализ имеющихся данных
\item Результаты оценивания logit и probit моделей
\item Прогнозирование с использованием Random Forest
\item Прогнозирование с использованием метода опорных векторов (SVM)
\item Графический анализ оценённых моделей
\item «Если бы я был пассажиром Титаника, то я спасся бы с вероятностью\ldots».

С помощью логит и пробит моделей необходимо построить 95\%-ый доверительный интервал для своей вероятности спасения. Для Random Forest требуется только точечная оценка вероятности спасения. Пол и возраст взять фактические, а остальные объясняющие переменные --- по своему желанию.
\end{enumerate}
\end{enumerate}


\section{2013-2014}

\subsection{Праздник 1. Вперед в рукопашную!}


\begin{enumerate}
\item Найдите длины векторов $a=(2,1,1)$ и $b=(-2,0,1)$ и косинус угла между ними.
\item Сформулируйте теорему о трёх перпендикулярах
\item Для матрицы

$A=\left(%
\begin{array}{ccc}
  -2 & 0 & 0 \\
  0 & 3 & 4 \\
  0 & 4 & 9 \\
\end{array}%
\right)$ \\

\begin{enumerate}
\item Найдите собственные числа и собственные векторы матрицы.
\item Найдите обратную матрицу, $A^{-1}$, ее собственные векторы и собственные числа.
\item Представьте матрицу $A$ в виде $A=CDC^{-1}$, где $D$ --- диагональная матрица.
\item Представьте $A^{2013}$ в виде произведения трёх матриц.
\end{enumerate}

\item Матрицы $A$ и $B$ таковы, что $\det(AB)$, $\det(BA)$, $\tr(AB)$ и $\tr(BA)$ определены. Возможно ли что $\det(AB)\neq \det(BA)$? Возможно ли, что $\tr(AB)\neq \tr(BA)$? Если неравенство возможно, то приведите пример.

\item Вася и Петя независимо друг от друга решают тест по теории вероятностей. В тесте всего два вопроса. На каждый вопрос два варианта ответа. Петя знает решение каждого вопроса с вероятностью $0{,}4$. Если Петя не знает решения, то он отвечает равновероятно наугад. Вася знает решение каждого вопроса с вероятностью $0{,}7$. Если Вася не знает решения, то он отвечает равновероятно наугад.
\begin{enumerate}
\item Какова вероятность того, что Петя правильно ответил на оба вопроса?
\item Какова вероятность того, что Петя правильно ответил на оба вопроса, если его ответы совпали с Васиными?
\item Чему равно математическое ожидание числа Петиных верных ответов?
\item Чему равно математическое ожидание числа Петиных верных ответов, если его ответы совпали с Васиными?
\end{enumerate}

\item Для случайных величин $X$ и $Y$ заданы следующие значения: $\E(X)=1$, $\E(Y)=4$, $\E(XY)=8$, $\Var(X)=\Var(Y)=9$. Для случайных величин $U=X+Y$ и $V=X-Y$ вычислите:
\begin{enumerate}
\item $\E(U)$, $\Var(U)$, $\E(V)$, $\Var(V)$, $\Cov(U,V)$
\item Можно ли утверждать, что случайные величины $U$ и $V$ независимы?
\end{enumerate}

\item Вася ведёт блог. Обозначим $X_i$ --- количество слов в $i$--ой записи. После первого года он по своим записям обнаружил, что $\bar{X}_{200}=95$ и выборочное стандартное отклонение равно $282$ слова. На уровне значимости $\alpha=0.10$ проверьте гипотезу о том, что $\mu=100$ против альтернативной гипотезы $\mu\neq 100$. Найдите также точное P-значение.



\end{enumerate}

\subsection{Праздник 2. Мегаматрица}

В рамках классической линейной модели с детерминистическими регрессорами найдите $\Var(\hb)$, $\Cov(\he,\hb)$, $\Cov(\he,\hy)$.

\subsection{Праздник 3. Базовая задача}

Пусть регрессионная модель $y_i = \beta_1 + \beta_2 x_{i2} + \beta_3 x_{i3} + \e_i$, $i = 1, \ldots, n$, задана в матричном виде при помощи уравнения $y = X \beta + \e$, где $\beta =  \begin{pmatrix}
\beta_1 & \beta_2 & \beta_3\\
\end{pmatrix} ^T$. Известно, что ошибки $\e$ нормально распределены с $\E \e = 0$ и $\Var (\e) = \sigma^2 \cdot I$. Известно также, что:

$y =  \begin{pmatrix}
1 \\
2 \\
3 \\
4 \\
5 \\
\end{pmatrix} $, $X =  \begin{pmatrix}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1 \\
\end{pmatrix} $

Для удобства расчётов ниже приведены матрицы:

$X^T X =  \begin{pmatrix}
5 & 3 & 1 \\
3 & 3 & 1 \\
1 & 1 & 1 \\
\end{pmatrix} $ и $(X^T X)^{-1} =  \begin{pmatrix}
0.5 & -0.5 & 0 \\
-0.5 & 1 & -0.5 \\
0 & -0.5 & 1.5 \\
\end{pmatrix} $.

\begin{enumerate}
\item Оценки $\hb$
\item Спрогнозируйте $y$, если  $x_2=1$ и $x_3=-2$
\item $TSS$, $ESS$, $RSS$, $R^2$
\item $\E (\hat{\sigma}^2)$
\item $\hat{\sigma}^2$
\item $\Var (\e_1)$
\item $\Var (\beta_1)$
\item $\Var (\hat{\beta}_1)$
\item $\widehat{\Var }(\hat{\beta}_1)$
\item $\Cov (\hat{\beta}_2, \hat{\beta}_3)$
\item $\widehat{\Cov }(\hat{\beta}_2, \hat{\beta}_3)$
\item $\Var (\hat{\beta}_2 - \hat{\beta}_3)$
\item $\widehat{\Var }(\hat{\beta}_2 - \hat{\beta}_3)$
\item $\Var (\beta_2 - \beta_3)$
\item Проверьте гипотезу $H_0$: $\b_1=1$ против гипотезы $H_a$: $\b_1\neq 1$ на уровне значимости $5\%$
\item Проверьте гипотезу $H_0$: $\b_2=0$ против гипотезы $H_a$: $\b_2\neq 0$ на уровне значимости $10\%$
\item Проверьте гипотезу $H_0$: $\b_2=\b_3$ против гипотезы $H_a$: $\b_2\neq \b_3$ на уровне значимости $5\%$
\end{enumerate}

\subsection{Праздник 4}

\begin{enumerate}
\item Пусть $y = X\beta + \e$ --- регрессионная модель, где $\beta = \begin{pmatrix} \beta_1 \\ \beta_2 \\ \beta_3 \end{pmatrix}$. Пусть $Z = XD$, где $D = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 1 \\ 0 & 0 & 1 \end{pmatrix}$. Рассмотрите «новую» регрессионную модель $y = Z\alpha + u$, где $\alpha = \begin{pmatrix} \alpha_1 \\ \alpha_2 \\ \alpha_3 \end{pmatrix}$. Определите, как выражаются «новые» МНК-коэффициенты через «старые».
\item  Рассмотрим модель $y_i = \beta_1+ \beta_2 x_i + \beta_3 w_i +\beta_4 z_i + \e_i$.  При оценке модели по $24$ наблюдениям оказалось, что $RSS=15$, $\sum (y_i-\bar{y}-w_i+\bar{w})^2=20$. На уровне значимости 1\% протестируйте гипотезу
\[
H_0:
\begin{cases}
\beta_2+\beta_3+\beta_4=1 \\
\beta_2=0 \\
\beta_3=1 \\
\beta_4=0
\end{cases}
\]
\item  По 47 наблюдениям оценивается зависимость доли мужчин занятых в сельском хозяйстве от уровня образованности и доли католического населения по Швейцарским кантонам в 1888 году.

\[Agriculture_i=\beta_1+\beta_2 Examination_i+\beta_3 Catholic_i+\varepsilon_i\]

<<echo=FALSE,message=FALSE>>=
h <- swiss
model1 <- glm(Agriculture~Examination+Catholic,data=h)
coef.t <- coeftest(model1)
dimnames(coef.t)[[2]] <-
    c("Оценка","Ст. ошибка",  "t-статистика", "P-значение")
coef.t <- coef.t[,-4]
coef.t[1,1] <- NA
coef.t[2,2] <- NA
coef.t[3,3] <- NA
@



<<results='asis',echo=FALSE>>=
xtable(coef.t)
@

\begin{enumerate}
\item Заполните пропуски в таблице
\item Укажите коэффициенты, значимые на 10\% уровне значимости.
\item Постройте 99\%-ый доверительный интервал для коэффициента при переменной Catholic
\end{enumerate}

\item Рассмотрим модель:
$y_i = \beta_1 + \beta_2 x_{1i} + \beta_3 x_{2i} + \beta_4 x_{3i} + \beta_5 x_{4i} + \e_i$.
По 20 наблюдениям оценены следующие регрессии:
\[
\underset{(s.e.)}{\hat{y_i}} = \underset{(0.15)}{10.01} + \underset{(0.06)}{1.05}x_1 + \underset{(0.04)}{2.06}x_2 + \underset{(0.06)}{0.49}x_3 - \underset{(0.06)}{1.31}x_4, RSS = 6.85
\]
\[
\underset{(s.e.)}{\widehat{y_i- x_1 - 2x_2}} = \underset{(0.15)}{10.00} + \underset{(0.07)}{0.50}x_3 - \underset{(0.06)}{1.32}x_4, RSS = 8.31
\]
\[
\underset{(s.e.)}{\widehat{y_i + x_1 + 2x_2}} = \underset{(3.62)}{9.93} + \underset{(1.48)}{0.56}x_3 - \underset{(1.42)}{1.50}x_4, RSS = 4310.62
\]
\[
\underset{(s.e.)}{\widehat{y_i - x_1 + 2x_2}} = \underset{(3.26)}{10.71} + \underset{(1.33)}{0.09}x_3 - \underset{(1.28)}{1.28}x_4, RSS = 3496.85
\]
\[
\underset{(s.e.)}{\widehat{y_i + x_1 - 2x_2}} = \underset{(1.25)}{9.22} + \underset{(0.51)}{0.97}x_3 - \underset{(0.49)}{1.54}x_4, RSS = 516.23
\]
На уровне значимости $5\%$ проверьте гипотезу $H_0: \begin{cases} \beta_2 = 1 \\ \beta_3 = 2 \end{cases}$ против альтернативной гипотезы $H_a: |\beta_2 - 1| + |\beta_3 - 2| \not= 0$.


\end{enumerate}



\subsection{Праздник 5. Максимальное правдоподобие}

\begin{enumerate}
\item  Случайные величины $X_{1}$, ..., $X_{n}$ --- независимы и одинаково распределены с функцией плотности $f(t)=\frac{\theta \cdot\left(\ln  t\right)^{\theta -1}}{t} $  при  $t\in
\left[1;e\right]$. По выборке из 100 наблюдений оказалось, что $\sum{\ln(\ln(X_{i}))}=-30$
\begin{enumerate}
\item Найдите ML оценку параметра $\theta$
\item Постройте 95\% доверительный интервал для $\theta$
\item С помощью LR, LM и W теста проверьте гипотезу о том, что $\theta=1$.
\end{enumerate}

\item Величины $X_{1}$, ..., $X_{n}$ --- независимы и нормально распределены, $N(\mu,\sigma^2)$. По 100 наблюдениям $\sum X_i=100$ и  $\sum X_i^2=900$.
\begin{enumerate}
\item Найдите ML оценки неизвестных параметров $\mu$ и $\sigma^2$.
\item Постройте 95\%-ые доверительные интервалы для $\mu$ и $\sigma^2$
\item С помощью LR, LM и W теста проверьте гипотезу о том, что $\sigma^2=1$.
\item С помощью LR, LM и W теста проверьте гипотезу о том, что $\sigma^2=1$ и одновременно $\mu=2$.
\end{enumerate}

\end{enumerate}

Всех участников правдоподобной контрольной с древнерусским эконометрическим праздником!

\vspace{20pt}

Сегодня \textbf{Аксинья-полухлебница}.

\vspace{20pt}

«На Аксинью гадали о ценах на хлеб в ближайшее время и на будущий урожай: брали печёный хлеб и взвешивали его сначала вечером, а потом утром. Коли вес оставался неизменным — цена на хлеб не изменится. Если за ночь вес уменьшался — значит, хлеб подешевеет, а если увеличивался, то подорожает»

\begin{flushright}
Wikipedia
\end{flushright}


\subsection{Переписывание кр 5. Максимальное правдоподобие}

\begin{enumerate}
\item  По совету Лисы Волк опустил в прорубь хвост и поймал 100 чудо-рыб. Веса рыбин независимы и имеют распределение Вейбулла, $f(x)=2\exp(-x^2/a^2)\cdot x/a^2$ при $x\geq 0$. Известно, что $\sum x_i^2=120$.
\begin{enumerate}
\item Найдите ML оценку параметра $a$
\item Постройте 95\% доверительный интервал для $a$
\item С помощью LR, LM и W теста проверьте гипотезу о том, что $a=1$.
\end{enumerate}

\item Как известно, Фрекен-Бок пьет коньяк по утрам и иногда видит привидения. За 110 дней имеются следующие статистические данные


\begin{tabular}{c|ccc}
Рюмок & 1 & 2 & 3 \\
\hline
Дней с привидениями & 10 & 25 & 20 \\
Дней без привидений & 20 &  25 & 10 \\
\end{tabular}

Вероятность увидеть привидение зависит от того, сколько рюмок коньяка было выпито утром, а именно, $p=\exp(a+bx)/(1+ \exp(a+bx))$, где $x$ --- количество рюмок, а $a$ и $b$ --- неизвестные параметры.
\begin{enumerate}
\item Найдите\footnote{Здесь потребуется максимизировать функцию в R. Если этот пункт не получился, то в последующих пунктах можно считать, что $\hat{a}=-1.5$, а $\hat{b}=0.5$. Это сильно округленные значения коэффициентов.} ML оценки неизвестных параметров $a$ и $b$.
\item Постройте 95\%-ые доверительные интервалы для $a$ и $b$
\item С помощью LR, LM и W теста проверьте гипотезу о том, что $b=0$.
\item С помощью LR, LM и W теста проверьте гипотезу о том, что $a=0$ и одновременно $b=0$.
\end{enumerate}

\end{enumerate}


\vspace{20pt}

Всем участникам переписывания правдоподобной контрольной счастья! Много!

\vspace{20pt}

Сегодня, 20 марта, \textbf{Международный День счастья}.


\subsection{Праздник 6. Гетероскедастичность}

\begin{enumerate}
\item Желая протестировать наличие гетероскедастичности в модели $y_i=\beta_1+\beta_2 x_i +\beta_3 z_i +\beta_4 w_i +\varepsilon_i$, эконометресса Глафира решила провести тест Уайта и получила  во вспомогательной регрессии $R^2=0.50$. Глафира строит модель удоя по 200 коровам. Помогите ей провести тест на уровне значимости 5\%.
\item На всякий случай эконометресса Глафира решила подстраховаться и провести тест Голдфельда-Квандта. Но она совсем забыла, как его делать. Напомните Глафире, как провести тест Голдфельда-Квандта, если она подозревает, что дисперсия $Var(\varepsilon_i)$ возрастает с ростом $z_i$. Чётко напишите гипотезы $H_0$, $H_a$, методику проведения теста, правило согласно которому отвергается или не отвергается $H_0$.
\item Имеются три наблюдения, $x=(1,2,2)'$, $y=(2,1,0)'$. Предполагая, что в модели $y_i=\beta x_i + \varepsilon_i$ имеется гетероскедастичность вида $Var(\varepsilon_i)=\sigma^2 x_i^4$ найдите:
\begin{enumerate}
\item Обычную МНК-оценку параметра $\beta$
\item Самую эффективную среди несмещенных оценку параметра $\beta$
\item Во сколько раз отличается истинная дисперсия этих двух оценок?
\item Во сколько раз отличаются оценки дисперсий этих оценок, если дисперсии оценивается без поправки на гетероскедастичность в обоих случаях?
\end{enumerate}
\end{enumerate}

\subsection{Большой Устный ЗАчёт}

\begin{enumerate}

\item Метод Наименьших Квадратов.

\begin{enumerate}
\item МНК-картинка
\item Нахождение всего-всего, если известен вектор $y$ и матрица $X$
  \end{enumerate}

\item Теорема Гаусса-Маркова
\begin{enumerate}
\item Формулировка с детерминистическими регрессорами
\item Доказательство с детерминистическими регрессорами
\item Формулировки со стохастическими регрессорами
\item Что даёт дополнительное предположение о нормальности $\varepsilon$?
\end{enumerate}

\item Проверка гипотез о линейных ограничениях
\begin{enumerate}
\item Проверка гипотезы о значимости коэффициента
\item Проверка гипотезы о значимости регрессии в целом
\item Проверка гипотезы об одном линейном соотношении с помощью ковариационной матрицы
\item Ограниченная и неограниченная модель
\item Тест Чоу на стабильность коэффициентов
\item Тест Чоу на прогнозную силу
\end{enumerate}

\item Метод максимального правдоподобия

\begin{enumerate}
\item Свойства оценок
\item Два способа получения оценки дисперсии
\item Три теста (LM, Wald, LR)
\item Выписать функцию ML для обычной регрессии
\item для AR(1) процесса
\item для MA(1) процесса
\item для логит модели
\item для пробит модели
\item для модели с заданным видом гетероскедастичности
\end{enumerate}

\item Мультиколлинеарность
\begin{enumerate}
\item Определение, последствия
\item Величины, измеряющие силу мультиколлинеарности
\item Методы борьбы
\item Сюда же: метод главных компонент, хотя он используется и для других целей
\end{enumerate}


\item Гетероскедастичность
\begin{enumerate}
\item Определение, последствия
\item Тесты, график
\item Стьюдентизированные остатки
\item HC оценки ковариации
\item GLS и FGLS
\end{enumerate}

\item Временные ряды
\begin{enumerate}
\item Стационарный временной ряд
\item ACF, PACF
\item Модель ARMA
\item Модель GARCH (не будет, не успели)
\end{enumerate}


\item Логит и пробит
\begin{enumerate}
\item Описание моделей
\item Предельные эффекты
\item Чувствительность, специфичность
\item Кривая ROC
\end{enumerate}

\item Эндогенность
\begin{enumerate}
\item Три примера: одновременность, пропущенные переменные, ошибки измерения
\item IV, двухшаговый МНК
\end{enumerate}


\item Модели панельных данных
\begin{enumerate}
\item  RE, FE, сквозная регрессии
\item  Тест Хаусмана
\end{enumerate}

\item Альтернативные методы. Уметь объяснить суть метода. Уметь реализовать его в R. %Если не считать упоминания Ridge regression, эти методы официально не входят в программу. Поэтому наивысшую оценку за Большой Устный Зачет можно получить не зная их. Но зная их можно подстраховать себя от ошибки на остальных задачах.
\begin{enumerate}
\item Метод опорных векторов (не будет, не успели)
\item Классификационные деревья и случайный лес
%\item Ridge regression (не будет, не успели)
%\item LASSO (не будет, не успели)
%\item Квантильная регрессия (не будет, не успели)
%\item Байесовская регрессия (не будет, не успели)
\end{enumerate}


\item R. Можно принести файл со своей заготовкой, можно пользоваться Интернетом для поиска информации, но не для общения.
\begin{enumerate}
\item Загрузить данные из \verb|.csv| файла в R
\item Посчитать описательные статистики (среднее, мода, медиана и т.д.)
\item Построить подходящие описательные графики для переменных
\item Оценить линейную регрессию с помощью МНК. Провести диагностику на что-нибудь (гетероскедастичность, автокорреляцию, мультиколлинеарность).
\item Оценить logit, probit модели, посчитать предельные эффекты
\item Оценить ARMA модель
\item Выделить главные компоненты
\end{enumerate}


\end{enumerate}



\subsection{Экзамен.}

\begin{enumerate}
\item Регрессионная модель  задана в матричном виде при помощи уравнения $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что

$y=\left(
\begin{array}{c}
1\\
2\\
3\\
4\\
5
\end{array}\right)$,
$X=\left(\begin{array}{ccc}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1
\end{array}\right)$.


Для удобства расчетов приведены матрицы


$X'X=\left(
\begin{array}{ccc}
5 & 3 & 1\\
3 & 3 & 1\\
1 & 1 & 1
\end{array}\right)$ и $(X'X)^{-1}=\frac{1}{2}\left(
\begin{array}{ccc}
1 & -1 & 0 \\
-1 & 2 & -1 \\
0 & -1 & 3
\end{array}\right)$.

\begin{enumerate}
\item Найдите вектор МНК-оценок коэффициентов $\hb$.
\item Найдите несмещенную оценку для неизвестного параметра $\sigma^2$.
\item Проверьте гипотезу $\beta_2=0$ против альтернативной о неравенстве на уровне значимости 5\%

\end{enumerate}




\item По данным о пассажирах Титаника оценивается логит-модель. Зависимая переменная \verb|survived| равна 1, если пассажир выжил. Объясняющая переменная \verb|sexmale| равна 1 для  мужчин.

<<"titanic", results='asis'>>=
mod.tit <- glm(data = titanic, survived~age+sex, family = "binomial")
texreg(mod.tit, float.pos = "h!", label = "table:titanic")
@

\begin{enumerate}
\item Оцените вероятность выжить для женщины 20 лет
\item Оцените предельный эффект увеличения возраста для женщины 20 лет
\item С помощью какого метода оценивается логит-модель? Каким образом при этом получаются оценки стандартных ошибок коэффициентов?
\end{enumerate}


\item Теорема Гаусса-Маркова.

\begin{enumerate}
\item Аккуратно сформулируйте теорему Гаусса-Маркова для нестохастических регрессоров.
\item Поясните каждое из свойств оценок, фигурирующих в теореме.
\item Как меняются свойства оценок МНК при нарушении предпосылки теоремы о том, что дисперсия $\e_i$ постоянна?
\end{enumerate}


\item Рассмотрим временной ряд, описываемый MA(2) моделью,
\[
y_t=\gamma + \e_t+\alpha_1 \e_{t-1}+\alpha_2 \e_{t-2},
\]
где $\e_t$ --- белый шум с $\Var(\e_t)=\sigma^2$.

\begin{enumerate}
\item Является ли данный процесс стационарным? Что такое стационарный процесс?
\item Найдите автокорреляционную функцию данного процесса, $\rho(k)=\Corr(y_t,y_{t-k})$.
\item Выпишите функцию правдоподобия для данной модели в предположении нормальности $\e_t$.
\end{enumerate}



\item Рассмотрите модель $y_i=\beta x_i+\e_i$. Предположим, что все предпосылки классической линейной регрессионной модели выполнены. Модель оценивается с помощью МНК и получается оценка $\hb_{OLS}$.
В условиях мультиколлинеарности для снижения дисперсии оценки $\hb$ можно применять ряд методов, например, алгоритм «ridge regression». Он состоит в том, что при некотором фиксированном $\lambda\geq 0$ минимизируется по $\hb$ величина
\[
Q(\hb)=\sum_i (y_i-\hb x_i)^2+\lambda \hb^2
\]
\begin{enumerate}
\item Как выглядит МНК оценка $\hb_{OLS}$?
\item Как выглядит оценка методом «ridge regression», $\hb_{RR}$?
\item Верно ли, что оценка $\hb_{RR}$ является несмещенной только при $\lambda=0$?
\item (*) Верно ли, что всегда найдется такое $\lambda$, что среднеквадратичная ошибка оценки $\hb_{RR}$ будет меньше, т.е. $\E((\hb_{RR}-\beta)^2)<\E((\hb_{OLS}-\beta)^2)$?
\end{enumerate}


\end{enumerate}


\subsection{Пересдача экзамена}

\begin{enumerate}
\item Регрессионная модель  задана в матричном виде при помощи уравнения $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что

$y=\left(
\begin{array}{c}
1\\
2\\
3\\
4\\
5
\end{array}\right)$,
$X=\left(\begin{array}{ccc}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1
\end{array}\right)$.


Для удобства расчетов приведены матрицы


$X'X=\left(
\begin{array}{ccc}
5 & 3 & 1\\
3 & 3 & 1\\
1 & 1 & 1
\end{array}\right)$ и $(X'X)^{-1}=\frac{1}{2}\left(
\begin{array}{ccc}
1 & -1 & 0 \\
-1 & 2 & -1 \\
0 & -1 & 3
\end{array}\right)$.

\begin{enumerate}
\item Найдите вектор МНК-оценок коэффициентов $\hb$.
\item Найдите несмещенную оценку для неизвестного параметра $\sigma^2$.
\item Проверьте гипотезу $\beta_2=0$ против альтернативной о неравенстве на уровне значимости 5\%

\end{enumerate}




\item По данным о пассажирах Титаника оценивается логит-модель. Зависимая переменная \verb|survived| равна 1, если пассажир выжил. Объясняющая переменная \verb|sexmale| равна 1 для  мужчин.

<<"titanic_dup", results='asis'>>=
mod.tit <- glm(data=titanic,survived~age+sex,family="binomial")
texreg(mod.tit, float.pos="h!", label="table:titanic-2")
@

\begin{enumerate}
\item Оцените вероятность выжить для женщины 20 лет
\item Оцените предельный эффект увеличения возраста для женщины 20 лет
\item С помощью какого метода оценивается логит-модель? Каким образом при этом получаются оценки стандартных ошибок коэффициентов?
\end{enumerate}


\item Теорема Гаусса-Маркова.

\begin{enumerate}
\item Аккуратно сформулируйте теорему Гаусса-Маркова для нестохастических регрессоров.
\item Поясните каждое из свойств оценок, фигурирующих в теореме.
\item Как меняются свойства оценок МНК при нарушении предпосылки теоремы о том, что дисперсия $\e_i$ постоянна?
\end{enumerate}

\item Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{c|cccc}
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\

\hline
$i=1,\ldots, 50$ & $0.93$ & $2.02$ & $3.38$ & $145.85$ \\
$i=1,\ldots, 21$ & $1.12$ & $2.01$ & $3.32$ & $19.88$ \\
$i=22,\ldots, 29$ & $0.29$ & $2.07$ & $2.24$ & $1.94$ \\
$i=30,\ldots, 50$ & $0.87$ & $1.84$ & $3.66$ & $117.46$ \\
\end{tabular}

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием.

\begin{enumerate}
\item Предполагая гомоскедастичность остатков на уровне значимости 5\% проверьте гипотезу, что исследуемая зависимость одинакова на всех трёх частях всей выборки.
\item Протестируйте ошибки на гетероскедастичность на уровне значимости 5\%.
\item Какой тест можно на гетероскедастичность можно было бы использовать, если бы не было уверенности в нормальности остатков? Опишите пошагово процедуру этого теста.
\end{enumerate}

\end{enumerate}


\subsection{Домашняя работа 1. RLMS и гетероскедастичность}

\begin{enumerate}
\item Прочитайте про RLMS, \url{http://www.hse.ru/rlms/}

Посмотрите описание проекта. Пролистайте вестник RLMS, чтобы иметь представление о том, какие исследования можно строить на основе RLMS.

\item Скачайте любую волну RLMS по своему выбору. Скачайте описание переменных.

Пролистайте описание переменных. Там их больше тысячи. Попадаются довольно прикольные. Мне нравится \verb|pc9.6.5a|, «У Вас есть GPRS навигатор?»

\item Загрузите данные в R.

Данные RLMS выложены на сайте в формате SPSS. SPSS это потихоньку погибающий статистический пакет для домохозяек. Для чтения формата .sav в таблицу данных R можно сделать так
<<echo=TRUE, eval=FALSE>>=
library(foreign)
file.name<-"/home/boris/downloads/r20hall23c.sav"
h<-read.spss(file.name,to.data.frame=TRUE)
@
Первая команда, \verb|library(foreign)|, подгружает библиотеку R, в которой содержатся команды для чтения вражеских форматов, spss, stata, etc

Описания переменных при этом также загружаются в таблицу данных. Можно их выделить в отдельный вектор и прочитать, например, про переменную \verb|pc9.631a|.
<<echo=TRUE, eval=FALSE>>=
var.labels<-attr(h,"variable.labels")
var.labels["pc9.631a"]
@

\item Выберите любую количественную переменную в качестве зависимой и несколько переменных в качестве объясняющей.

Цель этой домашки скорее ознакомится с наличием мониторинга RLMS, поэтому можно не сильно заморачиваться с этим этапом. Хотя в реальности тут-то всё самое интересное и начинается. За оригинальные гипотезы будут плюшки. Кстати, неплохо бы дать выбранным переменным понятные названия.

\item Опишите выбранные переменные.

Постройте симпатичные графики. Посчитайте описательные статистики. Много ли пропущенных наблюдений? Есть ли что-нибудь интересненькое?

\item Постройте регрессию зависимой переменной на объясняющие.

Проверьте гипотезу о значимости каждого полученного коэффициента. Проверьте гипотезу о значимости регрессии в целом. Для нескольких коэффициентов (двух достаточно) постройте 95\%-ый доверительный интервал.

\item Разберитесь с возможным наличием гетероскедастичности в данных.

С какой переменной может быть связана дисперсия $\Var(\e_i)$? Проведите визуальный анализ на гетероскедастичность. Проведите формальные тесты на гетероскедастичность. Примените оценки дисперсии $\hat{\beta}$ устойчивые к гетероскедастичности. Прокомментируйте. Может помочь \url{http://bdemeshev.github.io/r_cycle/cycle_files/12_hetero.html}

\item Покажите буйство своей фантазии и аккуратность!

Не стоит думать, что побуквенное выполнение этих инструкций гарантирует оценку в десять баллов. Эконометрика --- это не ремесло, а искусство! Фантазируйте! Убедите меня в работе, что вы были на лекциях, даже если это так :) Аккуратность в виде подписанных осей на графиках, указанных единицах измерения также не повредит.

\item Срок сдачи --- 27 февраля 2014 года.

Работа принимается исключительно в печатном виде с применением грамотного программирования R + \LaTeX. Каждый день более поздней сдачи умножает оценку за работу на $0.8$.  Работа должна представлять слитный текст, код скрывать не нужно. В конце должна быть команда \verb|sessionInfo()|.



%\item Напишите свои пожелания и комментарии.

%Какие домашки хочется сделать? Что не ясно в курсе эконометрики? Содержательные комментарии позволяют получить бонус. Искусная лесть оценивается :)

\end{enumerate}




\subsection{Домашняя работа 2. Титаник}

% на будующий год:
% добавить вероятности в svm
% перегруппировать так, чтобы все прогнозы шли в конце
% и потребовать табличку texreg и сравнение всех моделей по kaggle


\begin{enumerate}

\item Зарегистрируйтесь на сайте \url{www.kaggle.com}  в конкурсе «Titanic: Machine Learning from Disaster». В работе укажите login, использованный при регистрации.

\item Проанализируйте данные графически и с помощью описательных статистик (среднее, мода, медиана и т.д.)

Прокомментируйте графики, обратите внимание на количество пропущенных значений.

\item Оцените logit и probit модели.

Приведите оценки моделей. Какие коэффициенты значимы? Прокомментируйте знак коэффициентов. Посчитайте и сравните предельные эффекты.

\item Оцените random forest и SVM модели.

Параметры методов подберите с помощью кросс-валидации. Можно применять любые другие подходы, не только random forest и SVM. Другой подход следует описать в тексте.


\item «Если бы я был пассажиром Титаника, то я спасся бы с вероятностью\ldots».

С помощью логит и пробит моделей постройте 95\%-ый доверительный интервал для вероятности своего спасения. Для random forest --- только точечный прогноз вероятности, для svm --- только прогноз типа «да»/«нет».


\item Подумайте, чем можно заполнить пропущенные значения. Заполните пропущенные значения и заново оцените logit, random forest и svm. Насколько сильно меняется качество оцененных моделей?


\item Сравните все использованные подходы по прогнозной силе на тестовой выборке с сайта. Какой оказался наилучшим?

\item При прогнозировании и расчете предельных эффектов используйте свои фактические пол и возраст, а остальные объясняющие переменные --- выбирайте согласно своей фантазии :)

\item Срок сдачи --- 30 апреля 2014 года.

Работа принимается исключительно в печатном виде с применением грамотного программирования R + \LaTeX. Каждый день более поздней сдачи умножает оценку за работу на $0.8$.  Работа должна представлять слитный текст, код скрывать не нужно. В конце должна быть команда \verb|sessionInfo()|.

\item Популярные ошибки прошлой домашки будут караться со всей строгостью военного времени!

Цикл заметок про R в помощь \url{http://bdemeshev.github.io/r_cycle/}.

\end{enumerate}


\section{2014-2015}

\subsection{Праздник номер 1}

{\Large Вперёд, в рукопашную! }

\begin{enumerate}
\item Сформулируйте теорему о трёх перпендикулярах и обратную к ней.
\item Для матрицы

$A=\left(%
\begin{array}{cc}
  3 & 4 \\
  4 & 9 \\
\end{array}%
\right)$ \\

\begin{enumerate}
\item Найдите собственные числа и собственные векторы матрицы.
\item Найдите обратную матрицу, $A^{-1}$, ее собственные векторы и собственные числа.
\item Представьте матрицу $A$ в виде $A=CDC^{-1}$, где $D$ --- диагональная матрица.
\item Найдите $A^{42}$
\item Не находя $A^{100}$ найдите $\tr(A^{100})$ и $\det(A^{100})$
\end{enumerate}



\item Игрок получает случайным образом 13 карт из колоды в 52 карты.
\begin{enumerate}
\item Какова вероятность, что у него как минимум два туза?
\item Каково ожидаемое количество тузов у игрока?
\item Какова вероятность, что у него как минимум два туза, если
известно, что у него есть хотя бы один туз?
\item Каково ожидаемое количество тузов у игрока, если известно, что у него на руках хотя бы один туз?
\end{enumerate}


\item В ходе анкетирования 100 сотрудников банка «Омега» ответили на вопрос о том, сколько времени они проводят на работе ежедневно. Среднее выборочное оказалось равно $9.5$ часам при выборочном стандартном отклонении $0.5$ часа.
\begin{enumerate}
\item Постройте 95\% доверительный интервал для математического ожидания времени проводимого сотрудниками на работе
\item Проверьте гипотезу о том, что в среднем люди проводят на работе 10 часов, против альтернативной гипотезы о том, что в среднем люди проводят на работе меньше 10 часов, укажите точное Р-значение.
\end{enumerate}

\end{enumerate}


\subsection{Праздник номер 2}


{\Large Паниковать на контрольной строго воспрещается! :)}

\begin{enumerate}

\item  По 47 наблюдениям оценивается зависимость доли мужчин занятых в сельском хозяйстве от уровня образованности и доли католического населения по Швейцарским кантонам в 1888 году.

\[Agriculture_i=\beta_1+\beta_2 Examination_i+\beta_3 Catholic_i+\varepsilon_i\]

<<echo=FALSE,message=FALSE>>=
h <- swiss
model1 <- glm(Agriculture~Examination+Catholic,data=h)
coef.t <- coeftest(model1)
dimnames(coef.t)[[2]] <-
    c("Оценка","Ст. ошибка",  "t-статистика", "P-значение")
coef.t <- coef.t[,-4]
coef.t[1,1] <- NA
coef.t[2,2] <- NA
coef.t[3,3] <- NA
@



<<results='asis',echo=FALSE>>=
xtable(coef.t)
@

\begin{enumerate}
\item Заполните пропуски в таблице
\item Укажите коэффициенты, значимые на 10\% уровне значимости.
\item Постройте 99\%-ый доверительный интервал для коэффициента при переменной Catholic
\end{enumerate}

\item В рамках классической линейной модели с неслучайными регрессорами найдите $\Var(\hat{\varepsilon})$, $\Cov(\hat{\beta},\hat{\varepsilon})$. Верно ли, что $\Cov(\hat{\varepsilon}_1,\hat{\varepsilon}_2)=0$?

<<echo=FALSE>>=
X <- model.matrix(model1)
B <- t(X) %*% X
colnames(B) <- NULL
rownames(B) <- NULL
XXm <- solve(B)
x <- xtable(B,align=rep("",ncol(B)+1),digits=0)
xm <- xtable(XXm,align=rep("",ncol(B)+1),digits = 5)
# print(xm, floating=FALSE, tabular.environment="bmatrix",
#      hline.after=NULL, include.rownames=FALSE, include.colnames=FALSE)
@



\item Эконометресса Ефросинья оценивала модель $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i$. Найдя матрицы $X'X$ и $(X'X)^{-1}$, она призадумалась\ldots

$X'X = \begin{bmatrix}{}
  47 & 775 & 1934 \\
  775 & 15707 & 23121 \\
  1934 & 23121 & 159570 \\
  \end{bmatrix}$,
$(X'X)^{-1}=\begin{bmatrix}{}
  0.26653 & -0.01067 & -0.00168 \\
  -0.01067 & 0.00051 & 0.00006 \\
  -0.00168 & 0.00006 & 0.00002 \\
  \end{bmatrix}$


\begin{enumerate}
\item Помогите Ефросинье найти количество наблюдений, $\bar{z}$, $\sum x_i z_i$, $\sum(x_i-\bar{x})(z_i-\bar{z})$
\item (*) Ефросинья решила зачем-то также оценить модель $x_i = \gamma_1 + \gamma_2 z_i + u_i$. Как она может найти RSS в новой модели в одно арифметическое действие?
\end{enumerate}

\item Регрессионная модель  задана в матричном виде при помощи уравнения $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что

$y=\left(
\begin{array}{c}
1\\
2\\
3\\
4\\
2
\end{array}\right)$,
$X=\left(\begin{array}{ccc}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1
\end{array}\right)$.


Для удобства расчетов приведены матрицы


$X'X=\left(
\begin{array}{ccc}
5 & 3 & 1\\
3 & 3 & 1\\
1 & 1 & 1
\end{array}\right)$ и $(X'X)^{-1}=\frac{1}{2}\left(
\begin{array}{ccc}
1 & -1 & 0 \\
-1 & 2 & -1 \\
0 & -1 & 3
\end{array}\right)$.

\begin{enumerate}
\item Найдите вектор МНК-оценок коэффициентов $\hat{\beta}$.
\item Найдите несмещенную оценку для неизвестного параметра $\sigma^2$.
\item Проверьте гипотезу $\beta_2=0$ против альтернативной о неравенстве на уровне значимости 5\%
\end{enumerate}


\end{enumerate}


\subsection{Праздник номер 3}
Примечание: во всех задачах, если явно не сказано обратное, предполагается, что выполнены стандартные предпосылки классической линейной регрессионной модели.

\begin{enumerate}

\item  Рассмотрим следующую модель зависимости почасовой оплаты труда $W$ от уровня образования $Educ$, возраста $Age$, уровня образования родителей $Fathedu$ и $Mothedu$:
\[
\widehat{\ln W} = \hat{\beta}_1 + \hat{\beta}_2 Educ + \hat{\beta}_3 Age + \hat{\beta}_4 Age^2+ \hat{\beta}_5 Fathedu + \hat{\beta}_6 Mothedu
\]
\[
R^2 = 0.341, n = 27
\]
\begin{enumerate}
\item Напишите спецификацию регрессии с ограничениями для проверки статистической гипотезы $H_0: \beta_5 = 2\beta_4$
\item Дайте интерпретацию проверяемой гипотезе
\item Для регрессии с ограничением был вычислен коэффициент $R_{R}^2 = 0.296$. На уровне значимости $5\%$ проверьте нулевую гипотезу
\end{enumerate}



\item По ежегодным данным с 2002 по 2009 год оценивался тренд в динамике общей стоимости экспорта из РФ: $Exp_t=\beta_1+\beta_2t+\varepsilon_t$, где t --- год ($t=0$ для 2002 г., $t=1$ для 2003 г., \ldots, $t=7$
для 2009 г.), $Exp_t$ --- стоимость экспорта из РФ во все страны в млрд. долл. Оценённое уравнение  выглядит так: $\widehat{Exp}_t=111.9+43.2t$. Получены также оценки дисперсии случайной ошибки $\hat{\sigma}^2=4009$ и ковариационной матрицы оценок коэффициентов:
\[
\widehat{Var}(\hat{\beta})=\begin{pmatrix}
1671 & -334 \\
-334 & 95
\end{pmatrix}
\]

\begin{enumerate}
\item Постройте 95\%-ый доверительный интервал для коэффициента $\beta_2$
\item Спрогнозируйте стоимость экспорта на 2010 год и постройте 90\%-ый предиктивный интервал для прогноза.
\end{enumerate}
\item Имеется $100$ наблюдений. Исследователь Вениамин предполагает, что дисперсия случайной ошибки в последних $50$-ти наблюдениях в 4 раза выше, чем в первых $50$-ти, в частности $\Var(\varepsilon_1)=\sigma^2$, а $\Var(\varepsilon_{100})=4\sigma^2$. Вениамин оценивает модель $y_i=\beta x_i +\varepsilon_i$ с помощью МНК.
\begin{enumerate}
\item Найдите истинную дисперсию МНК оценки коэффициента $\beta$
\item Предложите более эффективную оценку $\hat{\beta}^{alt}$
\item Чему равна истинная дисперсия новой оценки?
\item Подробно опишите любой способ, который позволяет протестировать гипотезу о гомоскедастичности против предположения Вениамина о дисперсии.
\end{enumerate}

\item Закон больших чисел гласит, что если $z_i$ независимы и одинаково распределены, то $\plim \bar{z}_n = \E(z_1)$. Предположим, что регрессоры --- стохастические, а именно, наблюдения являются случайной выборкой (то есть отдельные наблюдения независимы и одинаково распределены), и  $\E(\varepsilon | X)=0$. Модель имеет вид:

\[
y_i=\beta_1 + \beta_2 x_i +\beta_3 w_i +\varepsilon_i
\]

\begin{enumerate}
\item Найдите $\E(\varepsilon)$, $\E(x_1 \cdot \varepsilon_1)$
\item Найдите $\plim \frac{1}{n}X'\varepsilon$
\item Найдите $\plim \frac{1}{n}X'X$
\item Докажите, что вектор МНК оценок $\hat{\beta}$ является состоятельным
\end{enumerate}


\item Эконометресса Эвридика хочет оценить модель $y_i=\beta_1 + \beta_2 x_i +\beta_3 z_i + \e_i$. К сожалению, она измеряет зависимую переменную с ошибкой. Т.е. вместо $y_i$ она знает значение $y_i^*=y_i+u_i$ и использует его в качестве зависимой переменной при оценке регрессии. Ошибки измерения $u_i$ некоррелированы между собой и с $\e_i$, имеют нулевое математическое ожидание и постоянную дисперсию $\sigma^2_u$.
\begin{enumerate}
\item Будут ли оценки Эвридики несмещенными?
\item Могут ли дисперсии оценок Эвридики быть ниже чем дисперсии МНК оценок при использовании настоящего $y_i$?
\item Могут ли оценки дисперсий оценок Эвридики быть ниже чем оценок дисперсий МНК оценок при использовании настоящего $y_i$?
\end{enumerate}


\end{enumerate}

\subsection{Миникр}

\subsubsection*{Миникр 5}

\begin{enumerate}
\item Как проверить гипотезу об одновременной незначимости всех коэффициентов регрессии кроме свободного члена? Укажите $H_0$, $H_a$, тестовую статистику и её распределение при верной $H_0$.
\item Рассмотрим модель $y=X\beta + \e$, где $n$ --- количество наблюдений, $k$ --- количество коэффициентов и $\e_i$ --- одинаково распределены и независимы.
\begin{enumerate}
\item Укажите вид матрицы $X$
\item Выпишите формулу для МНК оценки $\hb$
\item Выпишите формулу для ковариационной матрицы оценок $\hb$
\end{enumerate}
\item Опишите подробно тест Чоу на стабильность коэффициентов по двум наборам данных из $n_1$ и $n_2$ наблюдений соответственно. Число оцениваемых коэффициентов равно $k$.
\item Рассмотрим модель со свободным членом. Как вычисляются $R^2$ и скорректированный $R^2_{adj}$? Что может произойти с этими величинами при увеличении количества регрессоров? При уменьшении?
\item Какую гипотезу можно проверить, зная отношение $ESS/RSS$? Укажите $H_0$, $H_a$, тестовую статистику и её распределение при верной $H_0$.
\item Опишите подробно тест Чоу на прогнозную силу по двум наборам данных из $n_1$ и $n_2$ наблюдений соответственно. Число оцениваемых коэффициентов равно $k$.
\end{enumerate}


\subsection{Зачет. Базовый поток}

\begin{enumerate}
\item Сформулируйте теорему Гаусса-Маркова применительно к модели $y_i=\beta_1+\beta_2 x_i +\e_i$. Поясните смысл каждого используемого термина.

\item Как проверить гипотезу о том, что эксцесс случайной выборки совпадает с эксцессом нормально распределенной случайной величины? Аккуратно укажите проверяемые $H_0$, $H_a$, используемую статистику и её асимптотический закон распределения при верной $H_0$.

\item Рассмотрим модель спроса на продукцию трёх фирм $y_i=\beta_1+\beta_2 x_i +\beta_3 d_{i1} + \beta_4 d_{i2} + \e_i$. Здесь $x_i$ --- цена, а $y_i$ --- величина спроса.

Дамми переменные определены следующим образом:

\begin{tabular}{ccc}
 & $d_{i1}$ & $d_{i2}$  \\
\hline
Фирма 1 & 0 & 1  \\
Фирма 2 & 0 & 0  \\
Фирма 3 & 1 & 0  \\
\end{tabular}

\begin{enumerate}
\item Как проверить гипотезу, что спрос на продукцию трёх фирм совпадает? Укажите $H_0$, $H_a$, тестовую статистику, закон распределения статистики при верной $H_0$.
\item Дамми-переменные $d_{i1}$ и $d_{i2}$ заменяют на $d_{i3}$ и $d_{i4}$:

\begin{tabular}{ccc}
  & $d_{i3}$ & $d_{i4}$ \\
\hline
Фирма 1 &  0 & 0 \\
Фирма 2 &  1 & 0 \\
Фирма 3 &  1 & 1 \\
\end{tabular}


В новых переменных модель имеет вид $y_i=\beta_1'+\beta_2' x_i +\beta_3' d_{i1} + \beta_4' d_{i2} + \e_i$. Как новые коэффициенты $\beta'$ выражаются через старые коэффициенты $\beta$?
\end{enumerate}



\item Что можно сказать об оценке МНК $\hb_2$  в модели $y_i=\beta_1+\beta_2 x_i +\e_i$ при наличии ошибок измерений $x_i$? А при наличии ошибок измерений $y_i$?

\item Рассмотрим модель $y_i=\beta_1 + \beta_2 x_i +\e_i$, где $\e_i \sim N(0;\sigma^2)$.

\begin{enumerate}
\item Напишите выражения для оценок дисперсий и ковариации коэффициентов, т.е. $\hVar(\hb_1)$, $\hVar(\hb_2)$, $\hCov(\hb_1,\hb_2)$
\item Найдите математическое ожидание и дисперсию каждой из выписанных оценок
\item Какой закон распределения с точностью до масштабирования имеют эти оценки?
\end{enumerate}

\item Для модели данных $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ по 100 наблюдениям получены результаты:

<<results="asis">>=
x <- rnorm(100)
z <- rnorm(100)
x <- x - mean(x)
pre_model <- lm(z~x)
z <- resid(pre_model) # X'X is diagonal :)

y <- 2+3*x - 0.05*z + rnorm(100)
model <- lm(y~x+z)
#summary(model)
#vcov(model)
xtable(model)
@

\begin{enumerate}
\item Выпишите полученное уравнение регрессии
\item Укажите, какие коэффициенты значимы при $\alpha=0.05$
\item Проверьте $H_0$: $\beta_2-\beta_3=3$ предполагая, что оценки коэффициентов $\beta_2$ и  $\beta_3$ независимы
\end{enumerate}

\item Рассмотрим модель данных $y_i=\beta_1 + \beta_2 x_i + \e_i$, где $\e_i \sim N(0;\sigma^2)$.
\begin{enumerate}
\item Выпишите формулу для оценок коэффициентов и оценки дисперсии ошибок
\item Укажите математическое ожидание и дисперсию выписанных оценок
\item Для оценок коэффициентов укажите закон распределения
\item Для оценки дисперсии ошибок укажите закон распределения с точностью до масштабирования
\end{enumerate}

\end{enumerate}

\subsection{Зачет, 26.12.2014. Ликвидация безграмотности}

В этот день, 26 декабря 1919 года, совнарком РСФСР принял декрет «О ликвидации безграмотности в РСФСР». Всем желаю отметить этот день написанием грамотного зачета по эконометрике! Удачи!

\begin{enumerate}
\item Регрессионная модель  задана в матричном виде при помощи уравнения $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что

$y=\left(
\begin{array}{c}
1\\
2\\
3\\
4\\
5
\end{array}\right)$,
$X=\left(\begin{array}{ccc}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1
\end{array}\right)$.


Для удобства расчетов приведены матрицы


$X'X=\left(
\begin{array}{ccc}
5 & 2 & 1\\
2 & 2 & 1\\
1 & 1 & 1
\end{array}\right)$ и $(X'X)^{-1}=\frac{1}{3}\left(
\begin{array}{ccc}
1 & -1 & 0 \\
-1 & 4 & -3 \\
0 & -3 & 6
\end{array}\right)$.

\begin{enumerate}
\item Найдите вектор МНК-оценок коэффициентов $\hb$.
\item Найдите коэффициент детерминации $R^2$
\item Предполагая нормальное распределение вектора $\varepsilon$, проверьте гипотезу $H_0$: $\b_2=0$ против альтернативной $H_a$: $\b_2\neq 0$
\end{enumerate}

\item Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{c|cccc}
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\

\hline
$i=1,\ldots, 50$ & $0.93$ & $2.02$ & $3.38$ & $145.85$ \\
$i=1,\ldots, 21$ & $1.12$ & $2.01$ & $3.32$ & $19.88$ \\
$i=22,\ldots, 29$ & $0.29$ & $2.07$ & $2.24$ & $1.94$ \\
$i=30,\ldots, 50$ & $0.87$ & $1.84$ & $3.66$ & $117.46$ \\
\end{tabular}

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием.

\begin{enumerate}
\item Предполагая гомоскедастичность остатков на уровне значимости 5\% проверьте гипотезу, что исследуемая зависимость одинакова на всех трёх частях всей выборки.
\item Протестируйте ошибки на гетероскедастичность на уровне значимости 5\%.
\item Какой тест можно на гетероскедастичность можно было бы использовать, если бы не было уверенности в нормальности остатков? Опишите пошагово процедуру этого теста.
\end{enumerate}


\item По \Sexpr{nrow(flats)} наблюдениям оценена модель зависимости стоимости квартиры в Москве (в 1000\$) от общего метража и метража жилой площади.
<<"flats - 2", results='asis'>>=
model1 <- lm(price~totsp+livesp,data=flats)
report <- summary(model1)
coef.table <- report$coefficients
rownames(coef.table) <- c("Константа","Общая площадь", "Жилая площадь")
xtable(coef.table)
@

Оценка ковариационной матрицы $\widehat{Var}(\hat{\beta})$ имеет вид
<<"var hat - 2", results='asis'>>=
xtable(vcov(model1))
@

Оценка стандартной ошибки случайной составляющей, $\hat{\sigma}=\Sexpr{report$sigma}$.

\begin{enumerate}
\item Можно ли интерпретировать коэффициент при переменной $totsp$ как стоимость одного метра нежилой площади?
\item Проверьте гипотезу о том, что коэффициенты при регрессорах $totsp$ и $livesp$ равны.
\item Постройте 95\%-ый доверительный интервал для ожидаемой стоимости квартиры с жилой площадью $30$ м$^2$ и общей площадью $60$ м$^2$.
\item Постройте 95\%-ый прогнозный интервал для фактической стоимости квартиры с жилой площадью $30$ м$^2$ и общей площадью $60$ м$^2$.
\end{enumerate}

\item Аккуратно сформулируйте теорему Гаусса-Маркова
\begin{enumerate}
\item для нестохастических регрессоров
\item для стохастических регрессоров в предположении, что наблюдения являются случайной выборкой
\end{enumerate}




\end{enumerate}



\subsection{Домашняя работа 1. RLMS и гетероскедастичность}

\begin{enumerate}
\item Прочитайте про RLMS, \url{http://www.hse.ru/rlms/}

Посмотрите описание проекта. Пролистайте вестник RLMS, чтобы иметь представление о том, какие исследования можно строить на основе RLMS.

\item Скачайте любую волну RLMS по своему выбору. Скачайте описание переменных.

Пролистайте описание переменных. Там их больше тысячи. Попадаются довольно прикольные. Мне нравится \verb|pc9.6.5a|, «У Вас есть GPRS навигатор?»

\item Загрузите данные в R.

Данные RLMS выложены на сайте в формате SPSS. SPSS это потихоньку погибающий статистический пакет для домохозяек. Для удобства можно воспользоваться готовой функцией для чтения данных RLMS в пакете \verb|rlms|.
<<echo=TRUE, eval=FALSE>>=
library("rlms")
h <- read.rlms("/home/boris/downloads/r20hall23c.sav")
@
Про установку пакета \verb|rlms| можно прочитать на страничке \url{https://github.com/bdemeshev/rlms}

Описания переменных при этом также загружаются в таблицу данных. Можно их посмотреть:
<<echo=TRUE, eval=FALSE>>=
var_meta <- attr(h,"var_meta")
var_meta
@

\item Выберите любую количественную переменную в качестве зависимой и несколько переменных в качестве объясняющих.

Цель этой домашки скорее ознакомится с наличием мониторинга RLMS, поэтому можно не сильно заморачиваться с этим этапом. Хотя в реальности тут-то всё самое интересное и начинается. За оригинальные гипотезы будут плюшки. Кстати, неплохо бы дать выбранным переменным понятные названия.

\item Опишите выбранные переменные.

Постройте симпатичные графики. Посчитайте описательные статистики. Много ли пропущенных наблюдений? Есть ли что-нибудь интересненькое?

\item Постройте регрессию зависимой переменной на объясняющие.

Проверьте гипотезу о значимости каждого полученного коэффициента. Проверьте гипотезу о значимости регрессии в целом. Для нескольких коэффициентов (двух достаточно) постройте 95\%-ый доверительный интервал.

\item Разберитесь с возможным наличием гетероскедастичности в данных.

С какой переменной может быть связана дисперсия $\Var(\e_i)$? Проведите визуальный анализ на гетероскедастичность. Проведите формальные тесты на гетероскедастичность. Примените оценки дисперсии $\hat{\beta}$ устойчивые к гетероскедастичности. Прокомментируйте. Может помочь \url{http://bdemeshev.github.io/r_cycle/cycle_files/12_hetero.html}

\item Покажите буйство своей фантазии и аккуратность!

Не стоит думать, что побуквенное выполнение этих инструкций гарантирует оценку в десять баллов. Эконометрика --- это не ремесло, а искусство! Фантазируйте! Убедите меня в работе, что вы были на лекциях, даже если это не так :) Аккуратность в виде подписанных осей на графиках, указанных единицах измерения также не повредит.

\item Срок сдачи --- 12 января 2015 года.

Работа принимается исключительно в печатном виде с применением грамотного программирования R + \LaTeX или markdown. Каждый день более поздней сдачи умножает оценку за работу на $0.8$.  Работа должна представлять слитный текст, код скрывать не нужно. В конце должна быть команда \verb|sessionInfo()|.



%\item Напишите свои пожелания и комментарии.

%Какие домашки хочется сделать? Что не ясно в курсе эконометрики? Содержательные комментарии позволяют получить бонус. Искусная лесть оценивается :)

\end{enumerate}

\subsection{Экзамен. 15.06.15}


Больше двух столетий назад, 15 июня 1763 года Екатерина II издала манифест, запрещающий произнесение необдуманных речей, опасных для общественного спокойствия. Давайте применим этот манифест к экзамену по эконометрике!



\begin{enumerate}
\item Регрессионная модель  задана в матричном виде при помощи уравнения $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что

$y=\left(
\begin{array}{c}
1\\
2\\
3\\
4\\
5
\end{array}\right)$,
$X=\left(\begin{array}{ccc}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1
\end{array}\right)$.


Для удобства расчетов приведены матрицы


$X'X=\left(
\begin{array}{ccc}
5 & 3 & 1\\
3 & 3 & 1\\
1 & 1 & 1
\end{array}\right)$ и $(X'X)^{-1}=\frac{1}{2}\left(
\begin{array}{ccc}
1 & -1 & 0 \\
-1 & 2 & -1 \\
0 & -1 & 3
\end{array}\right)$.

\begin{enumerate}
\item Найдите вектор МНК-оценок коэффициентов $\hb$.
\item Найдите несмещенную оценку для неизвестного параметра $\sigma^2$.
\item Предполагая нормальность $\e_i$ проверьте гипотезу $\beta_2=0$ против альтернативной о неравенстве на уровне значимости 5\%

\end{enumerate}

\item Аккуратно сформулируйте теорему Гаусса-Маркова в парадигме стохастических регрессоров для ситуации случайной выборки

\item Немного вопросов про гетероскедастичность:
\begin{enumerate}
\item Что такое гетероскедастичность?
\item К каким последствиям она приводит?
\item Что можно предпринять в условиях гетероскедастичности и что эта мера даёт?
\end{enumerate}

\item Для MA(1) модели $y_t=3+\e_t+0.5\e_{t-1}$ посчитайте автокорреляционную и частную автокорреляционную функцию.

\item По 100 наблюдениям была оценена логит модель, $\hy_i^*=2.3-2x_i$.
\begin{enumerate}
\item Оцените вероятность $P(y_i=1)$ для $x_i=1$
\item Оцените предельный эффект $dP(y_i=1)/dx$ для $x_i=1$
\end{enumerate}

\item Рассмотрим классическую модель парной регрессии $y_i=\beta_1 + \beta_2 x_i + \e_i$ с нестохастическими регрессорами и нормальными остатками. Модель оценивается по 100 наблюдениям. Известно, что $F$-статистика, проверяющая гипотезу о незначимости регрессии в целом, равна 50.

Рассчитайте значения статистики множителей Лагранжа, $LM$, статистики Вальда, $W$, для проверки гипотезы о незначимости регрессии в целом.


\item Иван Андреевич Крылов хочет оценить, как зависит количество написанных им за день строчек басни, $y_i$, от количества съеденных булочек, $x_i$. То есть его интересует коэффициент $\beta_2$ в уравнении

\[
y_i=\beta_1+\beta_2 x_i + \e_i.
\]

Однако когда его окрыляет вдохновение, он очень невнимательно считает, поэтому величина $x_i$ ненаблюдаема. Кухарка и жена всегда готовы сказать, сколько булочек Крылов якобы съел за день. Эти величины содержат ошибку измерения, то есть $x_i^A=x_i+u_i^A$ и $x_i^B=x_i+u_i^B$.

Ошибки измерения $u_i^A$, $u_i^B$, случайная составляющая $\e_i$ независимы, $u_i^A \sim N(0,\sigma^2_A)$, $u_i^B \sim N(0,\sigma^2_B)$, $\e_i \sim N(0,\sigma^2_{\e})$. Иван Андреевич располагает информацией о 100 случайно выбранных днях.

\begin{enumerate}
\item Рассмотрим оценку $\hat{\beta}_2$, получаемую с помощью обычного МНК в регрессии $\hy_i=\hb_1+\hb_2 x_i^A$. Будет ли она состоятельной?
\item Рассмотрим двухшаговый МНК. На первом шаге строим регрессию $x_i^A$ на $x_i^B$ и получаем прогнозные значения $\hat{x}_i^A$. На втором шаге  оцениваем регрессию $\hy_i=\hb_1+\hb_2 \hat{x}_i^A$. Будет ли оценка $\hb_2$ состоятельной?
\end{enumerate}



\end{enumerate}

\section{2015-2016}

\subsection{Праздник номер 1. Вспомнить всё! 15.09.2015}

\begin{enumerate}
\item Найдите длины векторов $a=(1,1,1,1)$ и $b=(1,2,3,4)$ и косинус угла между ними. Найдите один любой вектор, перпенидкулярный вектору $a$.
\item Сформулируйте теорему о трёх перпендикулярах
\item Для матрицы

\[
A=\begin{pmatrix}
10 & 15 \\
15 & 26 \\
\end{pmatrix}
\]

\begin{enumerate}
\item Найдите собственные числа и собственные векторы матрицы
\item Найдите $\det (A)$, $\tr(A)$
\item Найдите обратную матрицу, $A^{-1}$, ее собственные векторы и собственные числа
\end{enumerate}

\item Известно, что $X$ --- матрица размера $n \times k$ и $n>k$, известно, что $X'X$ обратима. Рассмотрим матрицу $H=X(X'X)^{-1}X'$. Укажите размер матрицы $H$, найдите $H^{2015}$, $\tr(H)$, $\det(H)$, собственные числа матрицы $H$. Штрих означает транспонирование.

\item Для случайных величин $X$ и $Y$ заданы следующие значения: $\E(X)=1$, $\E(Y)=4$, $\E(XY)=8$, $\Var(X)=\Var(Y)=16$. Для случайных величин $U=X+Y$ и $V=X-Y$ вычислите:
\begin{enumerate}
\item $\E(U)$, $\Var(U)$, $\E(V)$, $\Var(V)$, $\Cov(U,V)$
\item Можно ли утверждать, что случайные величины $U$ и $V$ независимы?
\end{enumerate}

\item Вася ведёт блог. Обозначим $X_i$ --- количество слов в $i$--ой записи. После первого года он по 200 своим записям обнаружил, что $\bar{X}_{200}=95$ и выборочное стандартное отклонение равно $300$ слов. На уровне значимости $\alpha=0.15$ проверьте гипотезу о том, что $\mu=100$ против альтернативной гипотезы $\mu\neq 100$. Постройте $85$-ти процентный доверительный интервал для $\mu$.

\item Саша и Маша решали одну и ту же задачу. Саша правильно решает задачу с вероятностью $0.8$, Маша, независимо от Саши (!), с вероятностью $0.7$. Какова вероятность того, что Маша верно решила задачу, если задачу верно решил только кто-то один из них?

\end{enumerate}


\subsection{Праздник номер 1. Вспомнить всё! 15.09.2015, решение }


Автор решения: Кирилл Пономарёв

\begin{enumerate}

\item
Ну тут все понятно

\item
  Правильная формулировка: «Если прямая, проведенная на плоскости через основание наклонной, перпендикулярна её проекции, то она перпендикулярна и самой наклонной»



\item  % \renewcommand{\labelenumi}{(\alph{enumi})}

  \begin{enumerate}
  \item Собственные значения $\lambda_i$:
  \[
  \begin{vmatrix}
  10 - \lambda & 15 \\
  15 & 26 - \lambda
  \end{vmatrix}
  = \lambda^2 - 36\lambda + 35 = 0 \Rightarrow \lambda_1 = 1, \hspace{1mm} \lambda_2 = 35
  \]
  Собственный вектор $h$ соответствующий собственному значению $\lambda$ по определению:
  \[
  Ah = \lambda h \Rightarrow (A-\lambda\cdot I)h = 0
  \]


  То есть для $\lambda_1$:
  \[
  \begin{pmatrix}
  9 & 15 \\
  15 & 25
  \end{pmatrix}
  \cdot
  \begin{pmatrix}
  h_{11}  \\
  h_{21}
  \end{pmatrix}
  =
  \begin{pmatrix}
  0 \\
  0
  \end{pmatrix}
  \]
  Откуда:
  \[
  h_{11} = - \frac{5}{3}\cdot h_{21} \hspace{3mm} \text{то есть, например, вектор:}
  \begin{pmatrix}
  5\\
  -3
  \end{pmatrix}
  \]
  Аналогично находится собственный вектор, соответствующий $\lambda_2 = 35$

  \item Подставив $\lambda = 0$ в первый определитель, получим $\det(A)=35$, а $\tr(A) = \lambda_1 + \lambda_2 = 36$

  \item По определению $Ah = \lambda h$. Домножив на $A^{-1}$ (если она существует) обе части, получим:
  \[
  h = \lambda A^{-1} h \; \Rightarrow \; A^{-1}h = \frac{1}{\lambda}h
  \]



  То есть собственные значения для $A^{-1}$ это $1/\lambda_i$ а собственные векторы такие же, как и у матрицы $A$.
  \end{enumerate}



\item
  Размер матрицы $H$:
  \[
  \underset{n\times k}{X} \underset{k\times k}{(X'X)^{-1}} \underset{k\times n}{X'} = \underset{n\times n}{H}
  \]
  Заметим что $H^k = H$ для $k = 1,2,\ldots$
  \[
  H^2 = X\underbrace{(X'X)^{-1}X'X}_{{}=I}(X'X)^{-1}X' = X(X'X)^{-1}X' = H
  \]

  Такие матрицы называются идемпотентными, а для них: $\tr(A) = \rank(A)$. Найдем след, пользуясь свойством что $\tr(AB) = \tr(BA)$.
  \[
  \tr(H) = \tr(X(X'X)^{-1}X') = \tr((X'X)^{-1}XX') = \tr(I_k) = k
  \]
  То есть в данном случае $\rank(H) = k$. Так как $\rank(H) < n$, определитель этой матрицы равен 0.

  Для того чтобы найти собственные числа ($\lambda$), снова вспомним определение:
  \[
  Hv = \lambda v
  \]
  Домножив обе части этого уравнения на $H$, получим:
  \[
  H^2v = \lambda\cdot Hv \; \Leftrightarrow \; Hv = \lambda^2v
  \]
  Можем делать так сколько угодно раз, то есть если $\lambda$ -- собственное число матрицы $H$, то и $\lambda^k$ тоже. Значит это могут быть только 0 или 1. Тот факт, что 0 является собственным значением сразу вытекает из неполного ранга.



\item
  \begin{enumerate}
  \item
  \[
  \E(U) = \E(X+Y) = \E(X) + \E(Y) = 5
  \]

  \[
  \Cov(X,Y) = \E(XY) - \E(X)\E(Y) = 8 - 4 = 4
  \]

  \[
  \Var(U) = \Var(X) + \Var(Y) + 2\cdot \Cov(X, Y)= 16 + 16 + 2\cdot 4 = 40
  \]
  \[
  \E(V) = \E(X-Y) = \E(X) - \E(Y) = -3
  \]
  \[
  \Var(V) = \Var(X) + \Var(Y) - 2\cdot \Cov(X, Y)= 16 + 16 - 2\cdot 4 = 24
  \]
  \begin{multline}
  \Cov(U, V) = \Cov(X + Y, X-Y) = \Cov(X,X) - \Cov(X,Y) + \Cov(Y,X) - \Cov(Y,Y)= \\
   = \Var(X)-\Var(Y) = 0
  \end{multline}
  \item Нельзя, это не следует из равенства ковариации нулю. Можно было бы утверждать про независимость, если бы величины имели совместное нормальное распределение.

  \end{enumerate}



\item
  Ликбез: если известно, что сами $X_i$ нормальные, а истинной дисперсии нет, то используется распределение Стьюдента, и только в этом случае! Здесь же про распределение $X_i$ ничего не известно, но асимптотически (по ЦПТ) можно использовать нормальное.
  \[
  \sqrt{n}\cdot\frac{\overline{X}-\mu}{\sigma} \sim \cN(0, 1)
  \]
  Проверяем нулевую гипотезу против двухсторонней альтернативной:
  \[
  \begin{cases}
  H_0 :& \mu = 100 \\
  H_{al} :& \mu \ne 100
  \end{cases}
  \]
  Это значит что критические 15 процентов должны быть распределены по двум хвостам, поэтому нас интересуют $z_{0.075}$ и $z_{0.925}$. Рассчетная статистика:
  \[
  T = \sqrt{200}\cdot \frac{95 - 100}{300} = -0.24 > -1.44 = z_{0.075}
  \]
  Значит нулевая гипотеза не отвергается. Строим доверительный интервал:
  \[
  \P\left(z_{0.925} < \sqrt{n}\cdot\frac{\overline{X} - \mu}{\sigma} < z_{0.925}\right) = 0.85
  \]
  Так как распределение Стьюдента симметрично:
  \[
  \P\left(\overline{X} - z_{0.925}\cdot\frac{\sigma}{\sqrt{n}} < \mu < \overline{X} + z_{0.925}\cdot\frac{\sigma}{\sqrt{n}} \right) = 0.85
  \]
  Таким образом:
  \[
  \P(64.46  <\mu< 125.43)  = 0.85
  \]


\item
  Пусть событие $A$: «Маша верно решила задачу», а событие $B$: «Задачу решил только кто-то один». По формуле Байеса:
\[
  \P(A|B) = \frac{\P(B|A)\cdot\P(A)}{\P(B)}
\]

Здесь:
\[
\begin{array}{rl}
  \P(B|A) &= \P(\text{Саша не решил}) = 0.2\\
   \P(A) &= 0.7\\
   \P(B) &= 0.8\cdot0.3 + 0.7\cdot0.2 = 0.38
   \end{array}
\]
Поэтому:
\[
  \P(A|B) = \frac{0.2\cdot0.7}{0.38} = \frac{7}{19}
\]

\end{enumerate}

\subsection{Праздник номер 2, 10 ноября 2015}

\begin{enumerate}

\item В рамках классической линейной регрессионной модели $y=X\beta+ \varepsilon$, $\E(\varepsilon)=0$, $\Var(\varepsilon)=\sigma^2 \cdot I$, найдите: $\E(\hat\varepsilon)$, $\Var(\hat\varepsilon)$, $\Cov(\hat\varepsilon, y)$

\item Имеются данные:

\begin{tabular}{lll}
\toprule
$y_i$ & $x_i$ & $z_i$ \\
\midrule
1 & 2 & 1 \\
2 & -1 & 2 \\
3 & -3 & -3 \\
4 & 2 & 0 \\
\bottomrule
\end{tabular}

Предположим, что ошибки нормальны $N(0;\sigma^2)$ и независимы.

\begin{enumerate}
\item Оцените с помощью МНК модель $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i$
\item Найдите $RSS$, $TSS$, $ESS$ и $R^2$
\item Проверьте гипотезу о незначимости коэффициента $\hat\beta_2$ на уровне значимости 5\%.
\item Найдите оценку ковариационной матрицы коэффициентов $\widehat{\Var}(\hat\beta)$
\item Проверьте гипотезу $H_0: \beta_2 = \beta_3$ на уровне значимости 5\%.
\item Для четвёртого наблюдения постройте прогноз и найдите ошибку прогноза.
\end{enumerate}

\item Как могут измениться (могут ли увеличиться? уменьшиться?) $RSS$, $TSS$ и $ESS$ при добавлении дополнительного наблюдения? При добавлении дополнительного регрессора?

\item Эконометресса Агнесса оценила множественную регрессию $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i$. Потом она добавила два наблюдения к своей выборке: $y_{n+1}=1$, $x_{n+1}=2$, $z_{n+1}=3$ и $y_{n+2}=-1$, $x_{n+2}=1$, $z_{n+2}=2$. Как при этом изменились матрицы $X'X$ и $X'y$?


\item По 47 наблюдениям оценивается зависимость фертильности женщин от доли мужчин занятых в сельском хозяйстве и доли католического населения по Швейцарским кантонам в 1888 году.

\[Fertility_i=\beta_1+\beta_2 Examination_i+\beta_3 Catholic_i+\varepsilon_i\]

<<echo=FALSE, message=FALSE>>=
# library(Hmisc)
library(lmtest)
library(apsrtable)
library(xtable)
h <- swiss
model1 <- lm(Fertility~Examination+Catholic,data=h)
coef.t <- coeftest(model1)
dimnames(coef.t)[[2]] <- c("Оценка","Ст. ошибка",  "t-статистика", "P-значение")
coef.t <- coef.t[,-4]
coef.t[1,1] <- NA
coef.t[2,2] <- NA
coef.t[3,3] <- NA
@

<<echo=FALSE,results='asis'>>=
xtable(coef.t)
@

\begin{enumerate}
\item Заполните пропуски в таблице.
\item Укажите коэффициенты, значимые на 10\% уровне значимости.
\item Постройте 95\%-ый доверительный интервал для коэффициента при Examination
\end{enumerate}

\item Аккуратно сформулируйте (с «Если» и «то») теорему Гаусса-Маркова для случая нестохастических регрессоров.

\item Нарисуйте Самую Главную Картинку, иллюстрирующую метод наименьших квадратов для множественной регрессии. Отметьте на картинке $RSS$, $ESS$, $TSS$ и $R^2$

\item Эконометресса Ефросинья оценивала модель $y_i=\beta_1 + \beta_2 x_i + \beta_3 z_i + \varepsilon_i$. Найдя матрицы $X'X$ и $(X'X)^{-1}$, она призадумалась\ldots

$X'X = \begin{bmatrix}{}
  47 & 775 & 1934 \\
  775 & 15707 & 23121 \\
  1934 & 23121 & 159570 \\
  \end{bmatrix}$,
$(X'X)^{-1}=\begin{bmatrix}{}
  0.26653 & -0.01067 & -0.00168 \\
  -0.01067 & 0.00051 & 0.00006 \\
  -0.00168 & 0.00006 & 0.00002 \\
  \end{bmatrix}$


\begin{enumerate}
\item Помогите Ефросинье найти количество наблюдений, $\bar{z}$, $\sum x_i z_i$, $\sum(x_i-\bar{x})(z_i-\bar{z})$
\item Ефросинья решила зачем-то также оценить модель $x_i = \gamma_1 + \gamma_2 z_i + u_i$. Как выглядят матрицы $X'X$ и $X'y$ для новой модели?
\item (*) Как Ефросинья может найти RSS в новой модели в одно арифметическое действие?
\end{enumerate}


\item Как известно, $\hy=H y$, где матрица-шляпница $H$ задаётся формулой $H=X(X'X)^{-1}X'$.
\begin{enumerate}
\item Является ли вектор остатков $\he$ собственным вектором матрицы $H$? Если да, то какое собственное число ему соответствует?
\item Является ли вектор прогнозов $\hy$ собственным вектором матрицы $H$? Если да, то какое собственное число ему соответствует?
\item  Является ли регрессор $z$ (скажем, второй столбец матрицы $X$) собственным вектором матрицы $H$? Если да, то какое собственное число ему соответствует?
\end{enumerate}

\item Задача на компе с R.

Подключите библиотеку \verb|ggplot2| командой \verb|library("ggplot2")|. Рассмотрим набор данных по цене бриллиантов \verb|diamonds|. Оцените линейную модель зависимости цены бриллианта \verb|price| от массы \verb|carat| и глубины \verb|depth|. После оценки модели:
\begin{enumerate}
\item Поместите $R^2$ в переменную \verb|r_sq|
\item Поместите $RSS$ в переменную \verb|rss|
\item Поместите оценку коэффициента при \verb|carat| в переменную \verb|hb_carat|
\item Поместите прогнозы в вектор \verb|y_hat|
\end{enumerate}

\end{enumerate}


\subsection{Блокбастер, 28-12-2015}

В этот день, 28 декабря 1895 года, в индийском салоне «Гран-кафе» на бульваре Капуцинок в Париже состоялся публичный показ «Синематографа братьев Люмьер» :)

\begin{enumerate}
\item Регрессионная модель $y_i=\b_1 + \b_2 x_i + \b_3 z_i + \e_i$  задана в матричном виде  $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что

$y=\left(
\begin{array}{c}
1\\
2\\
3\\
4\\
5
\end{array}\right)$,
$X=\left(\begin{array}{ccc}
1 & 0 & 1 \\
1 & 0 & 1 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 0
\end{array}\right)$.


Для удобства расчетов приведены матрицы


$X'X=\left(
\begin{array}{ccc}
5 & 2 & 2\\
2 & 2 & 0\\
2 & 0 & 2
\end{array}\right)$ и $(X'X)^{-1}=\left(
\begin{array}{ccc}
1 & -1 & -1 \\
-1 & 1.5 & 1 \\
-1 & 1 & 1.5
\end{array}\right)$.

\begin{enumerate}
\item Найдите вектор МНК-оценок коэффициентов $\hb$.
\item Найдите коэффициент детерминации $R^2$
\item Предполагая нормальное распределение вектора $\varepsilon$, проверьте гипотезу $H_0$: $\b_3=0$ против альтернативной $H_a$: $\b_3\neq 0$ на уровне значимости 5\%.
\item Постройте точечный прогноз и 95\%-ый предиктивный интервал для $x_6=2$ и $z_6=0$.
\end{enumerate}


\item Рассмотрим модель со стохастическими регрессорами $y=X\b + \e$. При этом $\E(\e|X)=0$, как и положено, однако ошибки $\e$ хитро зависят друг от друга, и поэтому $\Var(\e|X)$ есть некоторая известная недиагональная матрица $V$. Несмотря на нарушение предпосылок теоремы Гаусса-Маркова Чак Норрис использует обычный МНК для получения оценок~$\hb$.

Найдите $\E(\hb|X)$, $\Var(\hb|X)$ и $\Cov(\hy, \he | X)$

\item Рассмотрим классическую линейную регрессионную модель:
\[
y_i = \b_1 + \b_2 x_i + \b_3 z_i + \e_i
\]

\begin{enumerate}
\item Огюст Люмьер утверждает, что при нестохастических регрессорах математические ожидания $\E(y_i)$ различны. Луи Люмьер утверждает, что при стохастических регрессорах и предпосылке о том, что наблюдения являются случайной выборкой, все $\E(y_i)$ равны между собой. Кто из них прав?
\item Помогите Луи Люмьеру найти $\plim \he_1$ и $\plim \hy_1$
\end{enumerate}


\item Рассмотрим классическую линейную регрессионную модель:
\[
y_i = \b_1 + \b_2 x_i + \b_3 z_i + \e_i
\]

Наблюдения является случайной выборкой. Истинная ковариция $\Cov(x_i, z_i)$ равна нулю. Мы оцениваем с помощью МНК две регрессии.

Регрессия 1:
\[
\hy_i = \hb_1 + \hb_2 x_i + \hb_3 z_i
\]

Регрессия 2:
\[
\hy_i = \hat \gamma_1 + \hat \gamma_2 x_i
\]

\begin{enumerate}
\item Верно ли, что $\hb_2$ совпадает с $\hat \gamma_2$?
\item Верно ли, что $\plim \hb_2 = \plim \hat \gamma_2$?
\end{enumerate}


\item Аккуратно опишите процедуру сравнения с помощью $F$-теста двух вложенных (ограниченной и неограниченной) линейных моделей:
\begin{enumerate}
\item Сформулируйте $H_0$ и $H_a$
\item Сформулируйте все предпосылки теста
\item Укажите способ подсчёта тестовой статистики
\item Укажите закон распределения тестовой статистики при верной $H_0$
\item Сформулируйте правило, по которому делается вывод об $H_0$
\end{enumerate}

\item Чтобы не выдать себя, Джеймс Бонд оценивает с помощью МНК только однопараметрические регрессии вида $y_i=\b x_i + \e_i$. Однако он знаком с теоремой Фриша-Вау.
\begin{enumerate}
\item Сколько подобных однопараметрических регрессий ему придется оценить, чтобы получить оценку коэффициента $\beta_3$ в множественной регрессии $y_i = \b_1 w_i + \b_2 x_i + \b_3 z_i + \e_i$?
\item Укажите, какие именно регрессии нужно построить для данной цели
\end{enumerate}

\end{enumerate}

\begin{center}
\includegraphics[scale=0.6]{50_bored.png}
\end{center}

\subsection{Максимально правдоподобно, 25-02-2016}

\begin{enumerate}
\thispagestyle{empty}

\item Как известно, Фрекен Бок любит пить коньяк по утрам. За прошедшие пять дней она записала, сколько рюмочек коньяка выпила утром, $x_i$, и видела ли она в этот день привидение, $y_i$,

\begin{tabular}{c|ccccc}
$y_i$ & 1 & 0 & 1 & 0 & 0 \\
\hline
$x_i$ & 2 & 1 & 3 & 1 & 0
\end{tabular}

Зависимость между $y_i$ и $x_i$ описывается пробит-моделью, $\P(y_i=1)=F(\beta_1 + \beta_2 x_i)$.

\begin{enumerate}
\item Выпишите логарифмическую функцию правдоподобия
\item Выпишите условия первого порядка для оценки $\beta_1$ и $\beta_2$
\end{enumerate}


\item Приведите пример небольшого набора данных для которого оценки логит модели $\P(y_i=1)=F(\beta_1 + \beta_2 x_i)$ не существуют. В наборе данных должны присутствовать хотя бы одно наблюдение $y_i=0$ и хотя бы одно наблюдение $y_i=1$.

\item Почему в пробит-модели предполагается, что $\e_i \sim \cN(0;1)$, а не $\e_i \sim \cN(0;\sigma^2)$ как в линейной регрессии?

\item Исследователь Вениамин пытается понять, как логарифм количества решённых им по эконометрике задач зависит от количества съеденных им пирожков. Для этого он собрал 100 наблюдений. Первые 50 наблюдений --- относятся к пирожкам с мясом, а последние 50 наблюдений --- к пирожкам с повидлом. Вениамин считает, что ожидаемое количество решённых задач не зависит от начинки пирожков, а только от их количества, т.е. $y_i = \beta x_i + u_i$. Однако он полагает, что для пирожков с мясом --- $u_i\sim \cN(0;\sigma^2_M)$, а для пирожков с повидлом --- $u_i\sim \cN(0;\sigma^2_J)$.

\begin{enumerate}
\item Выпишите логарифмическую функцию правдоподобия
\item Выпишите условия первого порядка для оценки $\beta$, $\sigma^2_M$, $\sigma^2_J$
\end{enumerate}

\item При оценке логит модели
\(
\P(y_i=1)=\Lambda(\b_1+\b_2 x_i)
\)
по 500 наблюдениям оказалось, что $\hb_1=0.7$ и $\hb_2=3$. Оценка ковариационной матрицы коэффициентов имеет вид
\[
\begin{pmatrix}
  0.04 & 0.01 \\
  0.01 & 0.09
\end{pmatrix}
\]

\begin{enumerate}
\item Проверьте гипотезу о незначимости коэффициента $\hb_2$
\item Найдите предельный эффект роста $x_i$ на вероятность $\P(y_i=1)$ при $x_i=-0.5$
\item Найдите максимальный предельный эффект роста $x_i$ на вероятность $\P(y_i=1)$
\item Постройте точечный прогноз вероятности $\P(y_i=1)$ если $x_i = -0.5$
\item Найдите стандартную ошибку построенного прогноза
\end{enumerate}

\item После долгих изысканий Вениамин пришёл к выводу, что $\beta=0$, т.е. что логарифм количества решенных им по эконометрике за вечер задач имеет нормальное распределение $y_i$ с математическим ожиданием ноль. Однако он по прежнему уверен, что дисперсия $y_i$ зависит от того, какие пирожки он ел в этом вечер. Для пирожков с повидлом $y_i \sim \cN(0;\sigma^2_J)$, а для пирожков с мясом --- $y_i\sim \cN(0;\sigma^2_M)$. Всего 100 наблюдений. Первые 50 вечеров относятся к пирожкам с мясом, последние 50 вечеров --- к пирожкам с повидлом:
\[
\sum_{i=1}^{50} y_i = 10, \; \sum_{i=1}^{50} y_i^2 = 100, \;
\sum_{i=51}^{100} y_i = -10, \; \sum_{i=51}^{100} y_i^2 = 300
\]
\begin{enumerate}
\item Найдите оценки $\sigma^2_M$, $\sigma^2_J$, которые получит Вениамин.
\item Помогите Вениамину проверить гипотезу $\sigma^2_M = \sigma^2_J$ с помощью тестов отношения правдоподобия, множителей Лагранжа и Вальда.
\end{enumerate}

\end{enumerate}


\subsection{Большой Устный ЗАчёт - 2016}

\begin{enumerate}

\item Метод Наименьших Квадратов.

\begin{enumerate}
\item МНК-картинка
\item Нахождение всего-всего, если известен вектор $y$ и матрица $X$
  \end{enumerate}

\item Теорема Гаусса-Маркова
\begin{enumerate}
\item Формулировка с детерминистическими регрессорами
\item Доказательство с детерминистическими регрессорами
\item Формулировки со стохастическими регрессорами
\item Что даёт дополнительное предположение о нормальности $\varepsilon$?
\item Теорема Фриша-Вау
\end{enumerate}

\item Проверка гипотез о линейных ограничениях
\begin{enumerate}
\item Проверка гипотезы о значимости коэффициента
\item Проверка гипотезы о значимости регрессии в целом
\item Проверка гипотезы об одном линейном соотношении с помощью ковариационной матрицы
\item Ограниченная и неограниченная модель
\item Тест Чоу на стабильность коэффициентов
\item Тест Чоу на прогнозную силу
\end{enumerate}

\item Метод максимального правдоподобия

\begin{enumerate}
\item Свойства оценок
\item Два способа получения оценки дисперсии
\item Три теста (LM, Wald, LR)
\item Выписать функцию ML для обычной регрессии
\item для AR(1) процесса
\item для MA(1) процесса
\item для логит модели
\item для пробит модели
\item для модели с заданным видом гетероскедастичности
\end{enumerate}

\item Мультиколлинеарность
\begin{enumerate}
\item Определение, последствия
\item Величины, измеряющие силу мультиколлинеарности
\item Методы борьбы
\item Сюда же: метод главных компонент, хотя он используется и для других целей
\end{enumerate}


\item Гетероскедастичность
\begin{enumerate}
\item Определение, последствия
\item Тесты, график
\item Стьюдентизированные остатки
\item HC оценки ковариации
\item GLS и FGLS
\end{enumerate}

\item Временные ряды
\begin{enumerate}
\item Стационарный временной ряд
\item ACF, PACF
\item Модель ARMA
\item ARIMA-SARIMA
\item Модель GARCH (не будет, не успели)
\end{enumerate}


\item Логит и пробит
\begin{enumerate}
\item Описание моделей
\item Предельные эффекты
\item Чувствительность, специфичность (не будет, не успели)
\item Кривая ROC (не будет, не успели)
\end{enumerate}

\item Эндогенность
\begin{enumerate}
\item Три примера: одновременность, пропущенные переменные, ошибки измерения
\item IV, двухшаговый МНК
\end{enumerate}


\item Модели панельных данных (не будет, не успели)
\begin{enumerate}
\item  RE, FE, сквозная регрессии
\item  Тест Хаусмана
\end{enumerate}

\item И ещё алгоритмы. Уметь объяснить суть метода. Уметь реализовать его в R. %Если не считать упоминания Ridge regression, эти методы официально не входят в программу. Поэтому наивысшую оценку за Большой Устный Зачет можно получить не зная их. Но зная их можно подстраховать себя от ошибки на остальных задачах.
\begin{enumerate}
\item Метод опорных векторов
\item Классификационные деревья и случайный лес
\item Ridge regression
\item LASSO
\item Квантильная регрессия
\item Байесовский подход к регрессии (не будет, не успели)
\end{enumerate}


\item R. Можно принести файл со своей заготовкой, можно пользоваться Интернетом для поиска информации, но не для общения.
\begin{enumerate}
\item Загрузить данные из \verb|.csv| файла в R
\item Посчитать описательные статистики (среднее, мода, медиана и т.д.)
\item Построить подходящие описательные графики для переменных
\item Оценить линейную регрессию с помощью МНК. Провести диагностику на что-нибудь (гетероскедастичность, автокорреляцию, мультиколлинеарность).
\item Оценить logit, probit модели, посчитать предельные эффекты
\item Оценить ARMA модель
\item Выделить главные компоненты
\end{enumerate}


\end{enumerate}


\end{document}
