# Гипотезы о нескольких ограничениях в регрессии {#many_restrictions}

* Датa __??/??/16__
* Конспект: Арсений Лысенко

## Примеры:

$H_{0}: \beta_{2} = 0$

$H_{0}: \beta_{2} = \beta_{7}$

\[
  H_{0}: \begin{cases}
  \beta_{2} = \beta_{7}\\
  \beta_{2} = \beta_{3}\\
  \end{cases}
\]

\[
  H_{0}: \begin{cases}
  \beta_{1} = 1\\
  \beta_{2} = 1\\
  \beta_{3} = 2\\
  \end{cases}
\]

## Проверка гипотез по шагам:
1. Строим регрессию, забыв про ограничения;
Получим $RSS_{UR} - RSS_{\text{Unrestricted}}$
2. Строим регрессию с учетом ограничений.\
Получим $RSS_{R} - RSS_{\text{Restricted}}$\

## Замечание:
МНК минимизирует RSS, поэтому безусловный RSS($RSS_{\text{UR}}$) будет меньше или равен условного RSS($RSS_{\text{R}}$).

## Теорема:
  Если выполнены предпоссылки теоремы Гаусса-Маркова, $H_{0}$ верна ии $\epsilon \sim N(0; \sigma * I)$, тогда:
  
  F = $\dfrac{(RSS_{R} - RSS{UR})/(\text{кол-во ограничений})}{RSS_{UR}/(n - k_{UR})}$
  $F \sim F_{\text{кол-во ограничений}; n - k_{UR}}$\
  где $k_{UR}$ - колличество коэффициентов в неограниченной модели.

## Упражнение:

  Харис пытается понять, что лучше помогает решать задачи по эконометрике:\
-поедание пирожков(штуки)\
-посещение лекций(академические часы)\

$problems_{t} = \beta_{1} + \beta_{2}lecture_{t} + \beta_{3}pie_{t} + u_{t}$\
$H_{0}: \beta_{2} = \beta_{3}$\
  Какую регрессию нужно оценить, чтобы найти $RSS_{R}$?

### Решение  
Согласно $H_{0}$ должно выполняться: $\beta_{2} = \beta_{3}$. Тогда:\
$problem_{i} = \beta_{1} + \beta_{2}(lecture_{i} + pie_{i}) + u_{i} = \beta_{1} + \beta_{2}lp_{i} + u_{i}$\
где  $lp_{i} = lecture_{i} + pie_{i}$\


А что, если Харис захочет проверить гипотезу о постоянной отдаче от масштабов? Как тогда будут выглядеть $H_{0}$ и ограниченная регрессия?\

UR: $ln problem_{i} = \gamma_{1} + \gamma_{2}\ln lecture_{i} + \gamma_{3}\ln pie_{i} + u_{i}$\

$problem_{i} = e^{\gamma_{1}}*lecture_{i}^{\gamma_{2}}*pie_{i}^{\gamma_{3}}*e^{u_{i}}$\

$H_{0} = \gamma_{1} + \gamma_{3} = 1$\

R: $ln problem_{i} = \gamma_{1} + \gamma_{2}\ln lecture_{i} + (1 - \gamma_{2})\ln pie_{i} + u_{i}$\
После преобразований получим:\
$(\ln problem_{i} - \ln pie_{i}) = \gamma_{1} + \gamma_{2} (\ln lecture_{i} - \ln pie_{i}) + u_{i}$\
Введём новые переменные:\
$\tilde{y_{i}} = \ln problem_{i} - \ln pie_{i}$\
$\tilde{x_{i}} = \ln lecture_{i} - \ln pie_{i}$\
Получим:\
$\tilde{y_{i}} = \gamma_{1} + \gamma_{2}\tilde{x_{i}} + u_{i}$

## Упражнение:
10 наблюдений\
$UR: RSS = 50  R^2 = 0,3$\
$problem_{i} = \beta_{1} + \beta_{2}lecture_{i} + \beta_{3}pie_{i} + u_{i}$\
\[
  H_{0}: \begin{cases}
  \beta_{2} = 0\\
  \beta_{3} = 0\\
  \end{cases}
\]

$H_{A}: \text{ хотя бы одна из } \beta_{2} \text{ и } \beta_{3} \ne 0$\

а) Как выглядит ограниченная регрессия?\
Чему равен $RSS_{R}$?\

б) Как выглядит $F$?\
Проверить $H_{0}$ на 5% уровне значимости.

### Решение:


а) $problem_{i} = \beta_{1} + \mu_{i}$\
$ESS = 0$\
$TSS = RSS$\
$R^2 = \dfrac{ESS}{TSS}$\

\[
R_{UR}^2 = 0,3 = \dfrac{TSS_{UR} - 50}{TSS_{UR}}
TSS_{UR} = 500/7 = 71
\]
$problem_{i} = \beta_{1} + \mu_{i}$\
Следовательно, $TSS_{R} = TSS_{UR} = RsS_{R} = 71$\

б) $F = \dfrac{(71-50)/2}{50/(10-3)} = \dfrac{10,5}{7} = 1,4$\

$F_{cr} = 4,7$. Получается, что основная гипотеза не отвергается.

## Упражнение:
Пусть Харис решил заново оценить модель после второго модуля чтобы понять, изменилась ли зависимость.\
В первом модуле было 10 наблюдений. Во втором модуле было 8 наблюдейний.\
Кроме того, известно:\
по двум модулям: $RSS = 150$\
по первому модулю: $RSS = 50$\
по второму модулю: $RSS = 70$\

$H_{0}$: зависимость не и зменилась\
$H_{A}$: зависимость изменилась, но осталась линейной\

а) Как выглядят ограниченная и неограниченная регрессии?\
б) $RSS_{UR} - ?$\
$RSS_{R} - ?$\
в) Проверить гипотезу $H_{0}$.

### Решение:
I модуль: $\beta_{1}, \beta_{2}, \beta_{3}$\
II модуль: $\gamma_{1}, \gamma_{2}, \gamma_{3}$\

\[
H_{0} = \begin{cases}
\beta_{1} = \gamma_{1}\\
\beta_{2} = \gamma_{2}\\
\beta_{3} = \gamma_{3}\\
\end{cases}
\]

Ограниченная модель строится по всем наблюдениям(по 18), то есть $RSS_{R} = 150$.\
Теперь рассмотрим неограниченную модель.\


\[
\begin{matrix} & X = \\ \end{matrix}
\begin{pmatrix}
1 & lecture_{1} & pie_{1} \\
\vdots & \vdots & \vdots \\
1 & lecture_n & pie_{n}
\end{pmatrix}
\]

\[y_{I} = X_{I}\cdot\beta + u_{I}
\]
\[y_{II} = X_{II}\cdot\beta + u_{I}
\]
\[
\begin{pmatrix}
y_{I} \\
y_{II}
\end{pmatrix}
\begin{matrix} = 
\begin{pmatrix}
X_{I} & ... & 0 & 0 \\
\vdots & \vdots & \vdots & \vdots \\
0 & 0 & ... & X_{II}
\end{pmatrix}
\cdot
\begin{pmatrix}
\beta_{1} \\ \beta_{2}\\ \beta_{2}\\ \gamma_{1} \\ \gamma_{2}\\ \gamma_{2}
\end{pmatrix}
+ 
\begin{pmatrix}
u_{I} \\ u_{II}
\end{pmatrix}
\end{matrix}
\] 

\[
y_{i} = \beta_{1} \cdot m^1_{i} + \beta_{2} \cdot lect_{i} \cdot m^1_{i} + \beta_{3} \cdot pie_{i}\cdot m^1_{i} + \gamma_{1} \cdot m^2_{i} + \gamma_{2} \cdot lect_{i} \cdot m^2_{i} + \gamma_{3} \cdot pie_{i}\cdot m^2_{i}
\]

\[
m^2 = 1 - m^1
\]

\[=> RSS_{UR} = RSS_{1} +  RSS_{} = 50 + 70 = 120\]

